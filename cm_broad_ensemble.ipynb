{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb13de7",
   "metadata": {},
   "source": [
    "\n",
    "# ViEWS 3 ensembles\n",
    "## Fatalities project, cm level\n",
    "This notebook evaluates the broad list of constituent models for the FCDO fatalities project. The final, stripped-down ensemble is computed in the cm_compute_ensemble notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e401e",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a04c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "import views_dataviz\n",
    "from views_runs import storage, ModelMetadata\n",
    "from views_runs.storage import store, retrieve, list, fetch_metadata\n",
    "from views_forecasts.extensions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca33422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages from Predicting Fatalies repository\n",
    "\n",
    "from HurdleRegression import *\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "\n",
    "from FetchData import FetchData, RetrieveFromList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "\n",
    "run_id = 'Fatalities001'\n",
    "dev_id = 'Fatalities001'\n",
    "EndOfHistory = 507\n",
    "RunGeneticAlgo = False\n",
    "level = 'cm'\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "#steps = [1,2,3,4,5,6,7,8,9,10,11,12,15,18,21,24] # Which steps to train and predict for\n",
    "#fi_steps = [1,3,6,12,36] # Which steps to present feature importances for\n",
    "#steps = [1,12,24,36]\n",
    "fi_steps = [1,3,6,12,36]\n",
    "#steps = [1,6,36]\n",
    "#fi_steps = [1,6,36]\n",
    "\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,444)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(445,492)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(493,504)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS'\n",
    "overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Tables/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 3 decimal places in output display\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "# Don't wrap repr(DataFrame) across additional lines\n",
    "pd.set_option(\"display.expand_frame_repr\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c1219b",
   "metadata": {},
   "source": [
    "##Â Retrieve models and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the ensemble\n",
    "# First item in dictionary is model name, second run id for development run\n",
    "ShortList = True\n",
    "# Short list of models:\n",
    "ModelsToRead = ['fat_baseline_rf',\n",
    "                'fat_conflicthistory_hurdle_lgb',\n",
    "                'fat_topics_rf',\n",
    "                'fat_hh20_Markov_glm']\n",
    "\n",
    "ModelList = []\n",
    "\n",
    "# Read in list with models from model development notebook\n",
    "\n",
    "gitname = 'ModelList_cm_wide_' + dev_id + '.csv'\n",
    "ModelList_df = pd.read_csv(gitname)\n",
    "#ModelList_df.head(40)\n",
    "\n",
    "if ShortList:\n",
    "    ModelList_df = ModelList_df[ModelList_df['modelname'].isin(ModelsToRead)].copy()\n",
    "# Int\n",
    "ModelList = ModelList_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for model in ModelList:\n",
    "    print(i,model['modelname'])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bbcfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "\n",
    "ModelList = RetrieveStoredPredictions(ModelList, steps, EndOfHistory, run_id)\n",
    "\n",
    "ModelList = CalibratePredictions(ModelList, EndOfHistory, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08dc701",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bddaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction target\n",
    "# In this particular ensemble available in model 0\n",
    "stored_modelname_calib = level + '_' + ModelList[0]['modelname'] + '_calib'\n",
    "stored_modelname_test = level + '_' + ModelList[0]['modelname'] + '_test'\n",
    "target = {\n",
    "        'y_calib':  pd.DataFrame.forecasts.read_store(stored_modelname_calib, run=run_id)['ln_ged_sb_dep'],\n",
    "        'y_test':  pd.DataFrame.forecasts.read_store(stored_modelname_test, run=run_id)['ln_ged_sb_dep']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9d1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrating calibration\n",
    "model = ModelList[0]\n",
    "print(model['modelname'])\n",
    "col = 'step_pred_1'\n",
    "period = 'test'\n",
    "\n",
    "print(model[f'{period}_df_calibrated'][col].describe())\n",
    "print(model[f'predictions_{period}_df'][col].describe())\n",
    "\n",
    "plt.scatter(model[f'predictions_{period}_df'][col],model[f'{period}_df_calibrated'][col])\n",
    "#plt.show()\n",
    "\n",
    "overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Figures/PredictionPlots/'\n",
    "filename = overleafpath + 'Calibration_example_' + model['modelname'] + '.png'\n",
    "plt.savefig(filename, dpi=300)\n",
    "#overleafpath = '~/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Figures/PredictionPlots/'\n",
    "#filename = overleafpath + 'Calibration_example' + model['modelname'] + '.png'\n",
    "#plt.savefig(filename, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving revised model list in data frame form\n",
    "gitname = 'EnsembleMetaData_broad_cm_' + dev_id + '.csv'\n",
    "ModelList_df.to_csv(gitname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d74ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_inspect = ['step_pred_1','step_pred_6','step_pred_12','step_pred_36']\n",
    "ModelList[2]['predictions_calib_df'][cols_to_inspect].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f483cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unweighted average ensemble\n",
    "# The gam calibrated is basis currently\n",
    "     \n",
    "ensemble = {\n",
    "    'modelname': 'ensemble_unweighted',\n",
    "    'depvar': \"ln_ged_sb_dep\",\n",
    "    'loggeddepvar': True,\n",
    "    'predictions_file_calib': \"\",\n",
    "    'predictions_file_test': \"\",\n",
    "    'calib_df_calibrated':  ModelList[0]['calib_df_calibrated'].copy(),\n",
    "    'test_df_calibrated':   ModelList[0]['test_df_calibrated'].copy(),\n",
    "#        'future_df_calibrated': ModelList[0]['future_df_calibrated'].copy(),\n",
    "    'calib_df_cal_expand':  ModelList[0]['calib_df_cal_expand'].copy(),\n",
    "    'test_df_cal_expand':   ModelList[0]['test_df_cal_expand'].copy(),\n",
    "#        'future_df_cal_expand': ModelList[0]['future_df_cal_expand'].copy(),\n",
    "    'calibration_gam': []\n",
    "}\n",
    "\n",
    "n_models = 1\n",
    "for model in ModelList:\n",
    "    ensemble['calib_df_calibrated'] = ensemble['calib_df_calibrated'].add(model['calib_df_calibrated'])\n",
    "    ensemble['test_df_calibrated'] = ensemble['test_df_calibrated'].add(model['test_df_calibrated'])\n",
    "    ensemble['calib_df_cal_expand'] = ensemble['calib_df_cal_expand'].add(model['calib_df_cal_expand'])\n",
    "    ensemble['test_df_cal_expand'] = ensemble['test_df_cal_expand'].add(model['test_df_cal_expand'])\n",
    "    n_models = n_models + 1\n",
    "#n_models = 1\n",
    "    \n",
    "ensemble['calib_df_calibrated'] = ensemble['calib_df_calibrated'].divide(n_models)\n",
    "ensemble['test_df_calibrated'] = ensemble['test_df_calibrated'].divide(n_models)\n",
    "ensemble['calib_df_cal_expand'] = ensemble['calib_df_cal_expand'].divide(n_models)\n",
    "ensemble['test_df_cal_expand'] = ensemble['test_df_cal_expand'].divide(n_models)\n",
    "\n",
    "ModelList.append(ensemble)\n",
    "\n",
    "# Save ensemble predictions\n",
    "\n",
    "predstore_calib = level +  '_' + ensemble['modelname'] + '_calib'\n",
    "ensemble['calib_df_calibrated'].forecasts.set_run(run_id)\n",
    "ensemble['calib_df_calibrated'].forecasts.to_store(name=predstore_calib, overwrite = True)\n",
    "predstore_test = level +  '_' + ensemble['modelname'] + '_test'\n",
    "ensemble['test_df_calibrated'].forecasts.set_run(run_id)\n",
    "ensemble['test_df_calibrated'].forecasts.to_store(name=predstore_test, overwrite = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c6596",
   "metadata": {},
   "source": [
    "# Estimating ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "target['y_calib'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missingness\n",
    "N=51\n",
    "df = ModelList[0]['predictions_test_df']\n",
    "#df = pd.DataFrame(target['y_test'])\n",
    "for col in df.iloc[: , :N].columns:\n",
    "    print(col,len(df[col]), 'missing:', df[col].isnull().sum(), 'infinity:', np.isinf(df).values.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d4ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ablation MSE, calibration partition\n",
    "\n",
    "from numpy import array\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def ensemble_predictions(yhats, weights):\n",
    "    # make predictions\n",
    "    yhats = np.array(yhats)\n",
    "    # weighted sum across ensemble members\n",
    "    result = np.dot(weights,yhats)\n",
    "    return result\n",
    "\n",
    "def evaluate_ensemble(yhats, weights, test_y):\n",
    "    ensemble_y = ensemble_predictions(yhats,weights)\n",
    "    return mean_squared_error(ensemble_y, test_y)\n",
    "\n",
    "# normalize a vector to have unit norm\n",
    "def normalize(weights):\n",
    "    # calculate l1 vector norm\n",
    "    result = norm(weights, 1)\n",
    "    # check for a vector of all zeros\n",
    "    if result == 0.0:\n",
    "        return weights\n",
    "    # return normalized vector (unit norm)\n",
    "    return weights / result\n",
    "\n",
    "\n",
    "stepcols = ['ln_ged_sb_dep']\n",
    "for step in steps:\n",
    "    stepcols.append('step_pred_' + str(step))\n",
    "ensemble_mses = [] # List to hold unweighted ensemble mses \n",
    "\n",
    "# Count models, set up lists\n",
    "number_of_models = 0\n",
    "mlist = []\n",
    "for model in ModelList[0:-1]:\n",
    "    number_of_models = number_of_models + 1\n",
    "    model['Ablation_MSE']=[0] * (len(steps)+1)\n",
    "    mlist.append(model['modelname'])\n",
    "print('Models:',number_of_models)        \n",
    "\n",
    "# Compute unweighted ensemble mses\n",
    "for col in stepcols:\n",
    "#    print(col)\n",
    "    yhats = []\n",
    "    weights = []\n",
    "    for model in ModelList[0:-1]:\n",
    "        df_calib = model['calib_df_calibrated'][~np.isinf(model['calib_df_calibrated'][col])].fillna(0)\n",
    "        yhats.append(df_calib[col])\n",
    "        weights.append(1/number_of_models)\n",
    "    emse = evaluate_ensemble(yhats, weights, df_calib['ln_ged_sb_dep'])\n",
    "    ensemble_mses.append(emse)\n",
    "\n",
    "#print('Unweighted ensemble MSEs:',ensemble_mses)\n",
    "\n",
    "# Compute ablation scores\n",
    "colno = 0\n",
    "for col in stepcols:\n",
    "    print('Step',col)\n",
    "    weights = []\n",
    "    for model in ModelList[0:-1]: # Assuming the ablated ensemble exists!\n",
    "        model['calib_df_calibrated'] = model['calib_df_calibrated'].fillna(0)\n",
    "#        print('Model to compute ablation MSE for',model['modelname'])\n",
    "        yhats = []\n",
    "        weights = []\n",
    "        for abl_model in ModelList[0:-1]:\n",
    "            abl_model['calib_df_calibrated'] = abl_model['calib_df_calibrated'].fillna(0) # Not sure what is best to do with NAs\n",
    "            y = model['calib_df_calibrated']['ln_ged_sb_dep'][~np.isinf(model['calib_df_calibrated'][col])]\n",
    "            if model['modelname'] != abl_model['modelname']:\n",
    "#                print('Model in ablated ensemble', abl_model['modelname'])\n",
    "                df_calib = abl_model['calib_df_calibrated'][~np.isinf(abl_model['calib_df_calibrated'][col])]\n",
    "                yhats.append(df_calib[col])\n",
    "                weights.append(1/(number_of_models-1))\n",
    "        ablated_mse = evaluate_ensemble(yhats, weights, y)\n",
    "        Ablation_MSE = ensemble_mses[colno] - ablated_mse\n",
    "        \n",
    "#        print(model['modelname'], 'ablated_mse:', ablated_mse, 'ensemble mse:',ensemble_mses[colno],'Ablation:' ,Ablation_MSE)\n",
    "        model['Ablation_MSE'][colno] = Ablation_MSE\n",
    "    colno = colno + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ab1814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "mean(ModelList[0]['Ablation_MSE'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c35098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the ablation MSEfor pre-screening of ensemble inclusion\n",
    "# model['Include'] set to False if contribution is not positive in any of four step segments\n",
    "\n",
    "from statistics import mean, stdev\n",
    "m = 0\n",
    "for model in ModelList[:-1]:\n",
    "    model['Include'] = False\n",
    "    m_all = mean(model['Ablation_MSE'][1:36])\n",
    "    m_1 = mean(model['Ablation_MSE'][1:6])\n",
    "    m_2 = mean(model['Ablation_MSE'][7:12])\n",
    "    m_3 = mean(model['Ablation_MSE'][13:24])\n",
    "    m_4 = mean(model['Ablation_MSE'][25:36])\n",
    "    for pmean in [m_all, m_1, m_2, m_3, m_4]:\n",
    "        if pmean < 0:\n",
    "            model['Include'] = True\n",
    "    \n",
    "    print(m, model['Include'], model['modelname'], ', aMSE steps all, 1-6, 7-12, 13-24, 25-36', \n",
    "          f'{m_all:.4f}',f'{m_1:.4f}',f'{m_2:.4f}',f'{m_3:.4f}',f'{m_4:.4f}',)\n",
    "    m = m + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd255f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing dfs to hold the predictions\n",
    "# A list of dictionaries organizing predictions and information as one step per entry,\n",
    "# including a dataframe for each step with one column per prediction model\n",
    "StepEnsembles = []\n",
    "for col in stepcols[1:]:\n",
    "    Step_prediction = {\n",
    "        'step_pred': col,\n",
    "        'df_calib': pd.DataFrame(target['y_calib']),\n",
    "        'df_test': pd.DataFrame(target['y_test']),\n",
    "        'ensembles_calib': pd.DataFrame(target['y_calib']),\n",
    "        'ensembles_test': pd.DataFrame(target['y_test'])\n",
    "    }\n",
    "    for model in ModelList:\n",
    "        modelname = model['modelname']\n",
    "        Step_prediction['df_calib'][modelname] = model['calib_df_calibrated'][col]\n",
    "        Step_prediction['df_test'][modelname] = model['test_df_calibrated'][col]\n",
    "    StepEnsembles.append(Step_prediction)\n",
    "\n",
    "# Calculating unweighted average ensembles\n",
    "i = 0\n",
    "for col in stepcols[1:]:\n",
    "    # Unweighted average\n",
    "    StepEnsembles[i]['ensembles_test']['unweighted_average'] = StepEnsembles[i]['df_test'].drop('ln_ged_sb_dep', axis=1).mean(axis=1)\n",
    "    StepEnsembles[i]['ensembles_calib']['unweighted_average'] = StepEnsembles[i]['df_calib'].drop('ln_ged_sb_dep', axis=1).mean(axis=1)\n",
    "    i = i + 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e18061",
   "metadata": {},
   "source": [
    "# Correlation of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd21970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate \n",
    "meancorr_df = pd.DataFrame(StepEnsembles[0]['df_calib'].corr().mean(axis=1))\n",
    "for step in [2,5,11,23,35]:\n",
    "    colname = 'step_' + str(step+1)\n",
    "    meancorr_df[colname] = StepEnsembles[step]['df_calib'].corr().mean(axis=1)\n",
    "meancorr_df['average'] = meancorr_df.mean(axis=1)\n",
    "meancorr_df\n",
    "# Save the corr dfs\n",
    "dflist = [\n",
    "    (meancorr_df,'meancorr_df'), \n",
    "]\n",
    "\n",
    "path = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/MSEs/'\n",
    "for df in dflist:\n",
    "    filename = path + df[1] + '.csv'\n",
    "    df[0].to_csv(filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc713bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "level = 'cm'\n",
    "\n",
    "cols_to_see = ['lndepvar', 'fat_hh20_xgb', 'fat_hh20_hurdle_xgb','fat_hh20_rf','fat_hh20_xgbrf']\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set() # Setting seaborn as default style even if use only matplotlib\n",
    "path = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/PredictionPlots/'\n",
    "overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Figures/'\n",
    "cm = \"YlGnBu\" \n",
    "#cm = 'mako'\n",
    "#cm = 'rocket'\n",
    "fig, ((ax1, ax3), (ax6,ax12), (ax24,ax36)) = plt.subplots(3, 2, figsize=(30,30))\n",
    "for subplot in [(ax1,0),(ax3,2),(ax6,5),(ax12,11),(ax24,23),(ax36,35)]:\n",
    "    subplot[0].set_box_aspect(1)\n",
    "    sns.heatmap(StepEnsembles[subplot[1]]['df_calib'].corr(), ax=subplot[0], cmap=cm) \n",
    "    subplot_title=('step ' + str(subplot[1]+1))\n",
    "    subplot[0].set_title = subplot_title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "figname = overleafpath + 'Correlations/PredictionCorrelations_calib_' + level + '.png'\n",
    "fig.savefig(figname, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aa39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrdf = StepEnsembles[0]['df_test'].corr()\n",
    "corrdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b224ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "meancorr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f09026d",
   "metadata": {},
   "source": [
    "# Create sc predictions and country prediction tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0df8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList[0]['test_df_calibrated'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c33eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a set of step-combined series starting from a series of start months\n",
    "# -- to see how predictions react to events at different calendar times\n",
    "for model in ModelList:\n",
    "    print(model['modelname'])\n",
    "    df = model['test_df_calibrated']\n",
    "    last_in_training = 444\n",
    "    last_in_test = 492\n",
    "    # t_range specifies the duration of the step-combined series to construct\n",
    "    t_range = range(0, 48)\n",
    "    step_range = range(1,36)\n",
    "    model['sc_df'] = pd.DataFrame(df['ln_ged_sb_dep'])\n",
    "    for month in t_range:\n",
    "        # Create a column to hold predictions starting from a given \"last observed\" month\n",
    "        col = 'sc_' + str(last_in_training + month)\n",
    "#        print(col)\n",
    "        model['sc_df'][col] = np.NaN\n",
    "        for step in step_range:\n",
    "            if (last_in_training + month+step) <= last_in_test: # To avoid generating series beyond last month in partition\n",
    "                predcol = 'step_pred_' + str(step) # The column in the in-df that contains predictions for this step\n",
    "#                print('For month', last_in_training + month + step, 'use', predcol, last_in_training + step + month)\n",
    "                model['sc_df'][col].loc[[last_in_training + month + step], :] = df[predcol].loc[last_in_training + step + month,:].values\n",
    "    model['sc_df_smooth']=model['sc_df'].rolling(3,center=True).mean().groupby(level=1)   \n",
    "    # Sub-list of predictions by country \n",
    "\n",
    "    model['CountryList'] = []\n",
    "    countries = model['test_df_calibrated'].index.unique(level='country_id').tolist()\n",
    "    for cnt in range(250):\n",
    "        cntdict = {\n",
    "        'country_id': cnt,\n",
    "        'country_name': ''\n",
    "        }\n",
    "        if cnt in countries:\n",
    "            cntdict['country_id'] = cnt\n",
    "            cntdict['test_df_calibrated'] = model['test_df_calibrated'].xs(cnt, level='country_id').copy()\n",
    "            cntdict['sc_df'] = model['sc_df'].xs(cnt, level='country_id')\n",
    "            cntdict['sc_df_smooth'] = cntdict['sc_df'].copy()\n",
    "            predcols = cntdict['sc_df_smooth'].columns[1:]\n",
    "            cntdict['sc_df_smooth'][predcols] = cntdict['sc_df'][predcols].rolling(3,center=True).mean()\n",
    "            cntdict['sc_df_smooth'] = cntdict['sc_df_smooth'].fillna(cntdict['sc_df'])\n",
    "        model['CountryList'].append(cntdict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d936eeba",
   "metadata": {},
   "source": [
    "## Evaluation of constituent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72912449",
   "metadata": {},
   "outputs": [],
   "source": [
    "model['calib_df_calibrated'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b880099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of constituent models\n",
    "calculate_grpMSEs = False\n",
    "\n",
    "MSE_calib_all = []\n",
    "MSE_calib_zeros = []\n",
    "MSE_calib_nonzeros = []\n",
    "if calculate_grpMSEs:\n",
    "    MSE_calib_grp0 = []\n",
    "    MSE_calib_grp1 = []\n",
    "    MSE_calib_grp2 = []\n",
    "    MSE_calib_grp3 = []\n",
    "MSE_test_all = []\n",
    "MSE_test_zeros = []\n",
    "MSE_test_nonzeros = []\n",
    "MSE_test_exp_all = []\n",
    "MSE_test_exp_zeros = []\n",
    "MSE_test_exp_nonzeros = []\n",
    "\n",
    "for model in ModelList:\n",
    "    calib_all_line = [model['modelname']]\n",
    "    calib_zeros_line = [model['modelname']]\n",
    "    calib_nonzeros_line = [model['modelname']]\n",
    "    test_all_line = [model['modelname']]\n",
    "    test_zeros_line = [model['modelname']]\n",
    "    test_nonzeros_line = [model['modelname']]\n",
    "    test_exp_all_line = [model['modelname']]\n",
    "    test_exp_zeros_line = [model['modelname']]\n",
    "    test_exp_nonzeros_line = [model['modelname']]\n",
    "    print(model['modelname'])\n",
    "    model['mse_calib'] = []\n",
    "    model['mse_calib_zeros'] = []\n",
    "    model['mse_calib_nonzeros'] = []\n",
    "    model['mse_test'] = []\n",
    "    model['mse_test_zeros'] = []\n",
    "    model['mse_test_nonzeros'] = []\n",
    "    model['mse_test_exp'] = []\n",
    "    model['mse_test_exp_zeros'] = []\n",
    "    model['mse_test_exp_nonzeros'] = []\n",
    "    if calculate_grpMSEs:\n",
    "        calib_grp0_line = [model['modelname']]\n",
    "        calib_grp1_line = [model['modelname']]\n",
    "        calib_grp2_line = [model['modelname']]\n",
    "        calib_grp3_line = [model['modelname']]\n",
    "        model['mse_calib_grp0'] = []\n",
    "        model['mse_calib_grp1'] = []\n",
    "        model['mse_calib_grp2'] = []\n",
    "        model['mse_calib_grp3'] = []\n",
    "    for cnt in model['CountryList']:\n",
    "        if cnt['country_id'] in countries:\n",
    "            cnt['mse'] = []\n",
    "    for col in stepcols[1:]:\n",
    "        # Remove from evaluation rows where [col] has infinite values (due to the 2011 split of Sudan)\n",
    "        df_calib = model['calib_df_calibrated'][~np.isinf(model['calib_df_calibrated'][col])]\n",
    "        df_test = model['test_df_calibrated'][~np.isinf(model['test_df_calibrated'][col])]\n",
    "        df_test_exp = model['test_df_cal_expand'][~np.isinf(model['test_df_cal_expand'][col])]\n",
    "\n",
    "        mse_calib = mean_squared_error(df_calib[col], df_calib['ln_ged_sb_dep'])\n",
    "        model['mse_calib'].append(mse_calib)\n",
    "        calib_all_line.append(mse_calib)\n",
    "        \n",
    "        mse_calib_zeros = mean_squared_error(df_calib[col].loc[df_calib['ln_ged_sb_dep'] == 0], df_calib['ln_ged_sb_dep'].loc[df_calib['ln_ged_sb_dep'] == 0])\n",
    "        model['mse_calib_zeros'].append(mse_calib_zeros)\n",
    "        calib_zeros_line.append(mse_calib_zeros)\n",
    "        \n",
    "        mse_calib_nonzeros = mean_squared_error(df_calib[col].loc[df_calib['ln_ged_sb_dep'] > 0], df_calib['ln_ged_sb_dep'].loc[df_calib['ln_ged_sb_dep'] > 0])\n",
    "        model['mse_calib_nonzeros'].append(mse_calib_nonzeros)\n",
    "        calib_nonzeros_line.append(mse_calib_nonzeros)\n",
    "        \n",
    "        \n",
    "        if calculate_grpMSEs:\n",
    "            # MSE for groups of cases based on baseline model predictions:\n",
    "            # Group 0\n",
    "            df_calib_grp0 = df_calib[onset_mask_calib[col]=='grp0']\n",
    "            mse_calib_grp0 = mean_squared_error(df_calib_grp0[col], df_calib_grp0['ln_ged_sb_dep'])\n",
    "            model['mse_calib_grp0'].append(mse_calib_grp0)\n",
    "            calib_grp0_line.append(mse_calib_grp0)\n",
    "\n",
    "            # Group 1\n",
    "            df_calib_grp1 = df_calib[onset_mask_calib[col]=='grp1']\n",
    "            mse_calib_grp1 = mean_squared_error(df_calib_grp1[col], df_calib_grp1['ln_ged_sb_dep'])\n",
    "            model['mse_calib_grp1'].append(mse_calib_grp1)\n",
    "            calib_grp1_line.append(mse_calib_grp1)\n",
    "\n",
    "            # Group 2\n",
    "            df_calib_grp2 = df_calib[onset_mask_calib[col]=='grp2']\n",
    "            mse_calib_grp2 = mean_squared_error(df_calib_grp2[col], df_calib_grp2['ln_ged_sb_dep'])\n",
    "            model['mse_calib_grp2'].append(mse_calib_grp2)\n",
    "            calib_grp2_line.append(mse_calib_grp2)\n",
    "\n",
    "            # Group 3\n",
    "            df_calib_grp3 = df_calib[onset_mask_calib[col]=='grp3']\n",
    "            mse_calib_grp3 = mean_squared_error(df_calib_grp3[col], df_calib_grp3['ln_ged_sb_dep'])\n",
    "            model['mse_calib_grp3'].append(mse_calib_grp3)\n",
    "            calib_grp3_line.append(mse_calib_grp3)\n",
    "        \n",
    "        \n",
    "#        mse_test = mean_squared_error(model['predictions_test_df'][col], model['predictions_test_df']['ln_ged_sb_dep'])\n",
    "        mse_test = mean_squared_error(df_test[col], target['y_test'])\n",
    "        model['mse_test'].append(mse_test)\n",
    "        test_all_line.append(mse_test)\n",
    "        \n",
    "        mse_zeros = mean_squared_error(df_test[col].loc[df_test['ln_ged_sb_dep'] == 0], df_test['ln_ged_sb_dep'].loc[df_test['ln_ged_sb_dep'] == 0])\n",
    "        model['mse_test_zeros'].append(mse_zeros)\n",
    "        test_zeros_line.append(mse_zeros)\n",
    "        \n",
    "        mse_nonzeros = mean_squared_error(df_test[col].loc[df_test['ln_ged_sb_dep'] > 0], df_test['ln_ged_sb_dep'].loc[df_test['ln_ged_sb_dep'] > 0])\n",
    "        model['mse_test_nonzeros'].append(mse_nonzeros)\n",
    "        test_nonzeros_line.append(mse_nonzeros)\n",
    "\n",
    "        mse_test_exp = mean_squared_error(df_test_exp[col], target['y_test'])\n",
    "        model['mse_test_exp'].append(mse_test_exp)\n",
    "        test_exp_all_line.append(mse_test_exp)\n",
    "        \n",
    "        mse_exp_zeros = mean_squared_error(df_test_exp[col].loc[df_test_exp['ln_ged_sb_dep'] == 0], df_test_exp['ln_ged_sb_dep'].loc[df_test_exp['ln_ged_sb_dep'] == 0])\n",
    "        model['mse_test_exp_zeros'].append(mse_exp_zeros)\n",
    "        test_exp_zeros_line.append(mse_exp_zeros)\n",
    "        \n",
    "        mse_exp_nonzeros = mean_squared_error(df_test_exp[col].loc[df_test_exp['ln_ged_sb_dep'] > 0], df_test_exp['ln_ged_sb_dep'].loc[df_test_exp['ln_ged_sb_dep'] > 0])\n",
    "        model['mse_test_exp_nonzeros'].append(mse_exp_nonzeros)\n",
    "        test_exp_nonzeros_line.append(mse_exp_nonzeros)\n",
    "\n",
    "\n",
    "        countries = model['test_df_calibrated'].index.unique(level='country_id').tolist()\n",
    "        for cnt in model['CountryList']:\n",
    "            if cnt['country_id'] in countries:\n",
    "                df_test = cnt['test_df_calibrated'][~np.isinf(cnt['test_df_calibrated'][col])]            \n",
    "                cnt_mse = mean_squared_error(df_test[col], df_test['ln_ged_sb_dep'])\n",
    "                cnt['mse'].append(cnt_mse)\n",
    "        \n",
    "    MSE_calib_all.append(calib_all_line)\n",
    "    MSE_calib_zeros.append(calib_zeros_line)\n",
    "    MSE_calib_nonzeros.append(calib_nonzeros_line)\n",
    "    if calculate_grpMSEs:\n",
    "        MSE_calib_grp0.append(calib_grp0_line)\n",
    "        MSE_calib_grp1.append(calib_grp1_line)\n",
    "        MSE_calib_grp2.append(calib_grp2_line)\n",
    "        MSE_calib_grp3.append(calib_grp3_line)\n",
    "    MSE_test_all.append(test_all_line)\n",
    "    MSE_test_zeros.append(test_zeros_line)\n",
    "    MSE_test_nonzeros.append(test_nonzeros_line)\n",
    "    MSE_test_exp_all.append(test_exp_all_line)\n",
    "    MSE_test_exp_zeros.append(test_exp_zeros_line)\n",
    "    MSE_test_exp_nonzeros.append(test_exp_nonzeros_line)\n",
    "    \n",
    "MSE_calib_all_df = pd.DataFrame(MSE_calib_all, columns=stepcols) \n",
    "MSE_calib_all_df.set_index('ln_ged_sb_dep', inplace=True)\n",
    "MSE_calib_zeros_df = pd.DataFrame(MSE_calib_zeros, columns=stepcols) \n",
    "MSE_calib_zeros_df.set_index('ln_ged_sb_dep', inplace=True)\n",
    "MSE_calib_nonzeros_df = pd.DataFrame(MSE_calib_nonzeros, columns=stepcols) \n",
    "MSE_calib_nonzeros_df.set_index('ln_ged_sb_dep', inplace=True)\n",
    "if calculate_grpMSEs:\n",
    "    MSE_calib_grp0_df = pd.DataFrame(MSE_calib_grp0, columns=stepcols) \n",
    "    MSE_calib_grp1_df = pd.DataFrame(MSE_calib_grp1, columns=stepcols) \n",
    "    MSE_calib_grp2_df = pd.DataFrame(MSE_calib_grp2, columns=stepcols) \n",
    "    MSE_calib_grp3_df = pd.DataFrame(MSE_calib_grp3, columns=stepcols) \n",
    "MSE_test_all_df = pd.DataFrame(MSE_test_all, columns=stepcols)  \n",
    "MSE_test_zeros_df = pd.DataFrame(MSE_test_zeros, columns=stepcols)  \n",
    "MSE_test_nonzeros_df = pd.DataFrame(MSE_test_nonzeros, columns=stepcols)  \n",
    "MSE_test_exp_all_df = pd.DataFrame(MSE_test_exp_all, columns=stepcols)  \n",
    "MSE_test_exp_zeros_df = pd.DataFrame(MSE_test_exp_zeros, columns=stepcols)  \n",
    "MSE_test_exp_nonzeros_df = pd.DataFrame(MSE_test_exp_nonzeros, columns=stepcols)  \n",
    "\n",
    "print('All models done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f385c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MSE dfs\n",
    "dflist = [\n",
    "    (MSE_calib_all_df,'MSE_calib_all_df'),\n",
    "    (MSE_calib_zeros_df,'MSE_calib_zeros_df'),\n",
    "    (MSE_calib_nonzeros_df,'MSE_calib_nonzeros_df'),\n",
    "    (MSE_test_all_df,'MSE_test_all_df'),\n",
    "    (MSE_test_zeros_df,'MSE_test_zeros_df'),\n",
    "    (MSE_test_nonzeros_df,'MSE_test_nonzeros_df'),   \n",
    "    (MSE_test_exp_all_df,'MSE_test_exp_all_df'),\n",
    "    (MSE_test_exp_zeros_df,'MSE_test_exp_zeros_df'),\n",
    "    (MSE_test_exp_nonzeros_df,'MSE_test_exp_nonzeros_df')   \n",
    "]\n",
    "\n",
    "path = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/MSEs/'\n",
    "for df in dflist:\n",
    "    filename = path + df[1] + '.csv'\n",
    "    df[0].to_csv(filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fee1d2",
   "metadata": {},
   "source": [
    "## List global MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc975641",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ModelList:\n",
    "    print(model['modelname'])\n",
    "    print('MSE calibration partition:', model['mse_calib'])\n",
    "    print('MSE test partition:', model['mse_test'])\n",
    "    print('MSE test partition, zeros:', model['mse_test_zeros'])\n",
    "    print('MSE test partition, non-zeros:', model['mse_test_nonzeros'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57335b04",
   "metadata": {},
   "source": [
    "# Plotting performance as heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dc04ba",
   "metadata": {},
   "source": [
    "## Ablation MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of ablation MSEs\n",
    "# df to hold ablation MSEs\n",
    "import seaborn as sns\n",
    "abl_df = pd.DataFrame(0.0, index=np.arange(len(ModelList[0]['Ablation_MSE'])), columns=mlist)    \n",
    "for model in ModelList[0:-2]: # Assuming the ablated ensemble exists\n",
    "    abl_df[model['modelname']] = model['Ablation_MSE']\n",
    "abl_df = abl_df[1:].T\n",
    "abl_df.columns=stepcols[1:]\n",
    "\n",
    "#palette = 'Spectral'\n",
    "#plt.figure()\n",
    "palette = 'vlag'\n",
    "fig, ax =plt.subplots(1,figsize=(16,11))\n",
    "ax = sns.heatmap(abl_df, center=0, xticklabels=2, linewidths=.5, cmap=palette,square=True)\n",
    "\n",
    "overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Figures/Pred_Eval/'\n",
    "filename = overleafpath + 'Ablation_MSEs.png'\n",
    "plt.savefig(filename, dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a4c8d9",
   "metadata": {},
   "source": [
    "## Dataframes with country-specific MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52370ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a dataframe for each model, plotting with Matshow\n",
    "Countries_to_plot = [41,42,43,47,48,49,50,52,53,54,55,56,60,62,67,69,70,124,155,156,157,162]\n",
    "Namelist = ['Cote dIvoire','Ghana','Liberia','47','48','49','50',\n",
    "            '52','53','54','55','56','60','62','67',\n",
    "            '69','70','124','155','156','157','162']\n",
    "\n",
    "\n",
    "for model in ModelList:\n",
    "    listdata = []\n",
    "#    countries = list(EnsembleList[0]['test_df_calibrated'].index.unique(level='country_id'))\n",
    "    for cnt in Countries_to_plot:\n",
    "        row = [cnt] + model['CountryList'][cnt]['mse']\n",
    "        listdata.append(row)\n",
    "    colnames = ['Country'] + stepcols[1:]\n",
    "    model['CC_MSEs'] = pd.DataFrame(listdata,columns=colnames) \n",
    "    \n",
    "    plt.matshow(model['CC_MSEs'][stepcols[1:]])\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "    plt.xticks(steps)\n",
    "#    plt.yticks(Namelist)\n",
    "#    ax.set_yticks(Countries_to_plot)\n",
    "#    ax.set_yticklabels(NameList)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631990a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting prediction vs actuals\n",
    "#ModelSelection=[0,2,3,6,8,9,13,17:24,26:27,31,35, 37:38]\n",
    "\n",
    "\n",
    "plx = 2\n",
    "ply = 2\n",
    "fig, axs = plt.subplots(plx, ply, sharey=True,sharex=True,figsize=(13,12))\n",
    "#to do log scales, use numpy package for the scale value to plot in xticks\n",
    "log_scale_value = np.array([np.log1p(0), np.log1p(1), np.log1p(10), np.log1p(100), np.log1p(1000), np.log1p(10000)])\n",
    "log_scale_naming = ['0','1', '10', '100', '1000','10000']\n",
    "\n",
    "month = [487,488,489,490,491,492]\n",
    "step = 13\n",
    "predvar = 'step_pred_' + str(step)\n",
    "size = 20 \n",
    "\n",
    "fpx = 0\n",
    "fpy = 0\n",
    "model_data = []\n",
    "for model in [ModelList[-1],ModelList[-1],ModelList[-1],ModelList[-1]]:\n",
    "    print(model['modelname'], fpx, fpy)\n",
    "    print('Prediction mean: ', model['test_df_calibrated'][predvar].mean())\n",
    "    axs[fpx,fpy].scatter( model['test_df_calibrated']['ln_ged_sb_dep'].loc[month], model['test_df_calibrated'][predvar].loc[month],s=size, alpha=0.5)\n",
    "    axs[fpx,fpy].set_ylabel(model['modelname'], fontsize=10)\n",
    "    axs[fpx,fpy].set_xlabel('Actually observed', fontsize=10)\n",
    "    plt.xticks(log_scale_value, log_scale_naming, rotation=30)\n",
    "    plt.yticks(log_scale_value, log_scale_naming, rotation=30)\n",
    "    axs[fpx,fpy].grid(True)\n",
    "#    axs[fpx,fpy].\n",
    "#    axs[fpx,fpy].\n",
    "    if fpx==plx-1:\n",
    "        fpx = 0\n",
    "        fpy = fpy + 1\n",
    "    else:\n",
    "        fpx = fpx + 1\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Figures/PredictionPlots/'\n",
    "filename = overleafpath + 'PredictionVsActuals_cm_s' + str(step) + '.png'\n",
    "plt.savefig(filename, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the outliers\n",
    "df = model['test_df_calibrated']\n",
    "cols = ['ln_ged_sb_dep','step_pred_2']\n",
    "print(df[cols].loc[df['ln_ged_sb_dep']>np.log1p(1000)].loc[month].head(20))\n",
    "# 57: Ethiopia\n",
    "# 120: Somalia\n",
    "# 126: Azerbaijan (Nagorno-Karabakh)\n",
    "# 133: Afghanistan\n",
    "# 167: DRC\n",
    "# 220: Mali\n",
    "\n",
    "for i in [np.log1p(10), np.log1p(25), np.log1p(100), np.log1p(1000)]:\n",
    "    print('exp(', str(i),')', np.rint(np.expm1(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd35ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model['sc_df'].head()\n",
    "for month_id, cnt_df in model['sc_df'].groupby(level=1):\n",
    "    country_id = cnt_df.index.values[0][1]\n",
    "#    print(country_id)\n",
    "    model['sc_df_smooth']=model['sc_df'].rolling(3,center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Make a smoothed version\n",
    "    model['sc_df_smooth']=model['sc_df'].rolling(3,center=True).mean().groupby(level=1)\n",
    "#    model['sc_df_smooth'] = model['sc_df'].copy()\n",
    "#    for col in model['sc_df_smooth'].columns[1:]:\n",
    "#        model['sc_df_smooth'].col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e62dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot figures with predictions as they evolve over time\n",
    "# New version\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "#ModelSelection = [1,3,5,9,11]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 6)\n",
    "overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/PredictionPlots/'\n",
    "path = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/PredictionPlots/'\n",
    "\n",
    "log_scale_value = np.array([np.log1p(0), np.log1p(1), np.log1p(3), np.log1p(10), np.log1p(30), np.log1p(100),np.log1p(300),np.log1p(1000),np.log1p(3000)])\n",
    "log_scale_naming = ['0','1','3','10','30','100','300','1000','3000']\n",
    "month_value = np.array([445,451,457,463,469,475,481,487,492])\n",
    "month_name = ['Jan-17','Jul-17','Jan-18','Jul-18','Jan-19','Jul-19','Jan-20','Jul-20','Dec-20']\n",
    "first_month = 444\n",
    "\n",
    "CountryList = [\n",
    "    ('Angola',165,500),\n",
    "    ('Botswana',154,500),\n",
    "    ('BurkinaFaso',47,2000),\n",
    "    ('Burundi',155,2000),\n",
    "#    ('Cameroon',211,2000),\n",
    "    ('Chad',214,2000),\n",
    "    ('Congo',166,2000),\n",
    "    ('DR Congo',167,20000),\n",
    "    ('Egypt',222,5000),\n",
    "    ('Ethiopia',57,2000),\n",
    "    ('Gabon',169,500),\n",
    "    ('Iran',128,2000),\n",
    "    ('Israel',218,2000),\n",
    "    ('Jordan',62,2000),\n",
    "    ('Kenya',237,2000),\n",
    "    ('Lebanon',94,2000),\n",
    "    ('Libya',213,5000),\n",
    "    ('Madagascar',172,2000),\n",
    "    ('Mali',50,20000),\n",
    "    ('Mauritania',244,500),\n",
    "    ('Morocco',243,500),\n",
    "    ('Mozambique',162,2000),\n",
    "    ('Namibia',170,500),\n",
    "    ('Niger',78,2000),\n",
    "    ('Nigeria',79,20000),\n",
    "    ('Oman',119,2000),\n",
    "    ('Rwanda',156,2000),\n",
    "    ('Saudi Arabia',131,500),\n",
    "    ('South Africa',163,2000),\n",
    "    ('South Sudan',246,5000),\n",
    "    ('Sudan',245,2000),\n",
    "    ('Syria',220,50000),\n",
    "    ('Tanzania',242,500),\n",
    "    ('Uganda',235,2000),\n",
    "    ('Yemen',124,20000),\n",
    "    ('Zimbabwe',158,5000),\n",
    "]\n",
    "#t_range = range(0, 23)\n",
    "t_range = [0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36]\n",
    "#t_range = [0,3,6,9,12,15,18,21,24,27,30,33,36]\n",
    "    \n",
    "for model in ModelList:\n",
    "    print(model['modelname'])\n",
    "    # Calculate non-logged and cumulative series\n",
    "    for cnt in CountryList:\n",
    "#        print(cnt)\n",
    "        sc_df = model['CountryList'][cnt[1]]['sc_df_smooth']\n",
    "        months = sc_df.index.to_series()\n",
    "        sc_df_exp = sc_df.copy()\n",
    "        sc_df_cum = sc_df.copy()\n",
    "        # Loop over all steps for each country\n",
    "        for column in sc_df.columns:\n",
    "            sc_df_exp[column]=np.rint(np.expm1(sc_df[column]))\n",
    "            sc_df_cum[column]=sc_df_exp[column].cumsum(axis=0, skipna = True)\n",
    "        sc_df_cumtemp = sc_df_cum.copy()\n",
    "        # Set first value of an sc series to the cumulated count up to t-1 (cct1 below)\n",
    "        cumdepvar = sc_df_cum['ln_ged_sb_dep']#.shift(1) # A  cumulative dependent variable series\n",
    "        i = first_month + 1\n",
    "        for column in sc_df.columns[2:]:\n",
    "            cct1 = cumdepvar[i]\n",
    "            sc_df_cum[column]=sc_df_cum[column]+cct1\n",
    "            i = i + 1\n",
    "            \n",
    "        plt.clf()\n",
    "#        print('Country',cnt[0])\n",
    "        plt.bar(months, 'ln_ged_sb_dep', data=sc_df, color='.8')\n",
    "        for m in t_range:\n",
    "            series = 'sc_' + str(444+m)\n",
    "            plt.plot(months, series, data=sc_df, c=cm.hot(np.abs((m/60)+.2)))\n",
    "        plt.ylabel('Number of fatalities')\n",
    "        plt.yticks(log_scale_value, log_scale_naming, rotation=30)\n",
    "        plt.xticks(month_value, month_name, rotation=30)\n",
    "        plt.grid(axis='y')\n",
    "        plt.ylim([0,np.log1p(3000)])\n",
    "        plt.title = cnt[0]\n",
    "        filename = path + 'OverTime/' + model['modelname'] + '_' + cnt[0] + '.png'\n",
    "        plt.savefig(filename, dpi=200)\n",
    "\n",
    "        plt.clf()\n",
    "        plt.title = cnt[0]\n",
    "        plt.bar(months, 'ln_ged_sb_dep', data=sc_df_cum, color='.8')\n",
    "        for m in t_range:\n",
    "            series = 'sc_' + str(444+m)\n",
    "            plt.plot(months, series, data=sc_df_cum, c=cm.hot(np.abs((m/60)+.2)))\n",
    "        plt.ylabel('Cumulative (non-logged) fatalities')\n",
    "        plt.xticks(month_value, month_name, rotation=30)\n",
    "        plt.grid(axis='y')\n",
    "        plt.ylim([0,cnt[2]])\n",
    "    #    plt.show()\n",
    "        filename = path + 'Cumulative/' + model['modelname'] + '_' + cnt[0] + '.png'\n",
    "        plt.savefig(filename, dpi=200)\n",
    "\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figures showing development over time for Mali and Burkina Faso\n",
    "\n",
    "CountryList = [\n",
    "    ('BurkinaFaso',47,2000),\n",
    "    ('Mali',50,20000),\n",
    "    ('Ethiopia',57,2000),\n",
    "    ('Nigeria',79,20000),\n",
    "]\n",
    "t_range = [0] + steps\n",
    "\n",
    "   \n",
    "for model in ModelList:\n",
    "    print(model['modelname'])\n",
    "    # Calculate non-logged and cumulative series\n",
    "    for cnt in CountryList:\n",
    "#        print(cnt)\n",
    "        sc_df = model['CountryList'][cnt[1]]['sc_df_smooth']\n",
    "        months = sc_df.index.to_series()\n",
    "        sc_df_exp = sc_df.copy()\n",
    "        sc_df_cum = sc_df.copy()\n",
    "        # Loop over all steps for each country\n",
    "        for column in sc_df.columns:\n",
    "            sc_df_exp[column]=np.rint(np.expm1(sc_df[column]))\n",
    "            sc_df_cum[column]=sc_df_exp[column].cumsum(axis=0, skipna = True)\n",
    "        sc_df_cumtemp = sc_df_cum.copy()\n",
    "        # Set first value of an sc series to the cumulated count up to t-1 (cct1 below)\n",
    "        cumdepvar = sc_df_cum['ln_ged_sb_dep']#.shift(1) # A  cumulative dependent variable series\n",
    "        i = first_month + 1\n",
    "        for column in sc_df.columns[2:]:\n",
    "            cct1 = cumdepvar[i]\n",
    "            sc_df_cum[column]=sc_df_cum[column]+cct1\n",
    "            i = i + 1\n",
    "            \n",
    "        plt.clf()\n",
    "#        print('Country',cnt[0])\n",
    "        plt.ylabel('Number of fatalities')\n",
    "        plt.yticks(log_scale_value, log_scale_naming, rotation=30)\n",
    "        plt.xticks(month_value, month_name, rotation=30)\n",
    "        plt.grid(axis='y')\n",
    "        plt.ylim([0,np.log1p(3000)])\n",
    "        plt.title = cnt[0]\n",
    "        for m in t_range:\n",
    "            \n",
    "            plt.clf()\n",
    "    #        print('Country',cnt[0])\n",
    "            plt.ylabel('Number of fatalities')\n",
    "            plt.yticks(log_scale_value, log_scale_naming, rotation=30)\n",
    "            plt.xticks(month_value, month_name, rotation=30)\n",
    "            plt.grid(axis='y')\n",
    "            plt.ylim([0,np.log1p(3000)])\n",
    "            sc_df['truncated_ged_sb'] = sc_df['ln_ged_sb_dep'][0:m]\n",
    "            predseries = 'sc_' + str(444+m)\n",
    "            plt.title = cnt[0]\n",
    "            plt.bar(months, 'truncated_ged_sb', data=sc_df, color='.8')\n",
    "            plt.plot(months, predseries, data=sc_df, c=cm.hot(np.abs((m/60)+.2)))\n",
    "\n",
    "            filename = path + 'OverTime/Rolling/' + model['modelname'] + '_' + cnt[0] + '_' + str(444+m) + '.png'\n",
    "            plt.savefig(filename, dpi=200)\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6899120",
   "metadata": {},
   "source": [
    "# Uncertainty of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList[-1]['test_df_calibrated'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb83e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "months = [487, 488,489,490,491,492]\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 6)\n",
    "overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/PredictionPlots/'\n",
    "path = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/PredictionPlots/'\n",
    "\n",
    "df = ModelList[-1]['test_df_calibrated'].loc[months]\n",
    "                      \n",
    "\n",
    "bins = pd.IntervalIndex.from_tuples([(-1, 0.3), (0.3, 1.05), (1.05, 1.89), (1.89, 2.92), (2.92, 4.02), (4.02, 5.15), (5.15, 6.3), (6.3, 7.45), (7.45, 10)])\n",
    "df['fatalitybins_1'] = pd.cut(df['step_pred_1'],bins)\n",
    "df['fatalitybins_1'].describe()\n",
    "i = 0\n",
    "for value in [1,3,10,30,100,300,1000,3000]:\n",
    "    print('Count:', value, 'logged:', np.log1p(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29ca38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = (0.05, 0.10, 0.25,0.5,0.75, 0.9,0.95, 0.99)\n",
    "\n",
    "df['ged_sb_dep'] = np.expm1(df['ln_ged_sb_dep'])\n",
    "df['ged_sb_dep'].describe(percentiles = percentiles)\n",
    "df['exp_pred_2'] = np.expm1(df['step_pred_2'])\n",
    "df['exp_pred_13'] = np.expm1(df['step_pred_13'])\n",
    "bins2 = pd.IntervalIndex.from_tuples([(0, 3), (3, 10), (10, 30), (30, 100), (100, 300), (300, 1000), (1000, 100000)])\n",
    "bins2 = pd.IntervalIndex.from_tuples([(10, 30), (100, 300),  (1000, 100000)])\n",
    "bins2 = pd.IntervalIndex.from_tuples([(3, 10), (30, 100),  (300, 1000)])\n",
    "\n",
    "\n",
    "df['fatalitybins2_2'] = pd.cut(df['exp_pred_2'],bins2)\n",
    "df['fatalitybins2_2'].describe()\n",
    "\n",
    "df['fatalitybins2_13'] = pd.cut(df['exp_pred_13'],bins2)\n",
    "df['fatalitybins2_13'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecab336",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bin in bins:\n",
    "    print(bin)\n",
    "    print( df['ln_ged_sb_dep'][df['fatalitybins_1']==bin].describe(percentiles = percentiles))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214dd482",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "step=13\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "# Plot the orbital period with horizontal boxes\n",
    "sns.boxplot(x=\"ged_sb_dep\", y=\"fatalitybins2_13\", data=df,\n",
    "            whis=[5, 95], width=.9, palette=\"vlag\")\n",
    "\n",
    "# Add in points to show each observation\n",
    "sns.stripplot(x=\"ged_sb_dep\", y=\"fatalitybins2_13\", data=df,\n",
    "              size=4, color=\".3\", linewidth=0)\n",
    "\n",
    "# Tweak the visual presentation\n",
    "ax.xaxis.grid(True)\n",
    "ax.set(ylabel=\"Predicted number of fatalities\")\n",
    "ax.set(xlabel=\"Observed number of fatalities\")\n",
    "sns.despine(trim=True, left=True)\n",
    "\n",
    "overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Figures/PredictionPlots/'\n",
    "filename = overleafpath + 'PredictionUncertainty_cm_s' + str(step) + '.png'\n",
    "plt.savefig(filename, dpi=300)\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7823d6bd",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import contextily as ctx\n",
    "\n",
    "from views_dataviz import color\n",
    "from views_dataviz.map import utils\n",
    "from views_dataviz.map.presets import ViewsMap\n",
    "\n",
    "import sqlalchemy as sa\n",
    "from ingester3.config import source_db_path\n",
    "from ingester3.Country import Country\n",
    "from ingester3.extensions import *\n",
    "from ingester3.ViewsMonth import ViewsMonth\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Mapper2:\n",
    "    \"\"\"\n",
    "    `Map` takes basic properties and allows the user to consecutively add\n",
    "    layers to the Map object. This makes it possible to prepare mapping\n",
    "    \"presets\" at any level of layeredness that can be built on further.\n",
    "    \n",
    "    Mapper2 allows for the customizable addition of scaling to the map. \n",
    "    -re-add the code for labels later when i can test it\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    width: Integer value for width in inches.\n",
    "    height: Integer value for height in inches.\n",
    "    bbox: List for the bbox per [xmin, xmax, ymin, ymax].\n",
    "    frame_on: Bool for whether to draw a frame around the map.\n",
    "    title: Optional default title at matplotlib's default size.\n",
    "    figure: Optional tuple of (fig, size) to use if you want to plot into an\n",
    "        already existing fig and ax, rather than making a new one.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        width,\n",
    "        height,\n",
    "        bbox=None,\n",
    "        cmap=None,\n",
    "        frame_on=True,\n",
    "        title=\"\",  # Default title without customization. (?)\n",
    "        figure=None,\n",
    "    ):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.bbox = bbox  # xmin, xmax, ymin, ymax\n",
    "        self.cmap = cmap\n",
    "        if figure is None:\n",
    "            self.fig, self.ax = plt.subplots(figsize=(self.width, self.height))\n",
    "        else:\n",
    "            self.fig, self.ax = figure\n",
    "        self.texts = []\n",
    "        self.ax.set_title(title)\n",
    "\n",
    "        if frame_on:  # Remove axis ticks only.\n",
    "            self.ax.tick_params(\n",
    "                top=False,\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                right=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=False,\n",
    "            )\n",
    "        else:\n",
    "            self.ax.axis(\"off\")\n",
    "\n",
    "        if bbox is not None:\n",
    "            self.ax.set_xlim((self.bbox[0], self.bbox[1]))\n",
    "            self.ax.set_ylim((self.bbox[2], self.bbox[3]))\n",
    "\n",
    "    def add_layer(self, gdf, map_scale=False, map_dictionary=False, cmap=None, inform_colorbar=False, **kwargs):\n",
    "        \"\"\"Add a geopandas plot to a new layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        gdf: Geopandas GeoDataFrame to plot.\n",
    "        cmap: Optional matplotlib colormap object or string reference\n",
    "            (e.g. \"viridis\").\n",
    "        inform_colorbar: Set or overwrite colorbar with the current layer.\n",
    "            Not applicable when `color` is supplied in the kwargs.\n",
    "        map_scale: set a manual scale for the map. If missing defaults to the Remco procedure. \n",
    "        map_dictionary: set manual labels for the map. If missing defaults to the default labels.\n",
    "        **kwargs: Geopandas `.plot` keyword arguments.\n",
    "        \"\"\"\n",
    "        if \"color\" in kwargs:\n",
    "            colormap = None\n",
    "        else:\n",
    "            colormap = self.cmap if cmap is None else cmap\n",
    "            if inform_colorbar and \"column\" in kwargs:\n",
    "                if hasattr(self, \"cax\"):\n",
    "                    self.cax.remove()\n",
    "                if \"vmin\" not in kwargs:\n",
    "                    self.vmin = gdf[kwargs[\"column\"]].min()\n",
    "                else:\n",
    "                    self.vmin = kwargs[\"vmin\"]\n",
    "                if \"vmax\" not in kwargs:\n",
    "                    self.vmax = gdf[kwargs[\"column\"]].max()\n",
    "                else:\n",
    "                    self.vmax = kwargs[\"vmax\"]\n",
    "        \n",
    "        try: Mapper2.add_colorbar(self, colormap, min(map_scale), max(map_scale))\n",
    "        except: Mapper2.add_colorbar(self, colormap, self.vmin, self.vmax)\n",
    "        \n",
    "        try:\n",
    "            self.ax = gdf.plot(ax=self.ax, cmap=colormap, vmin=min(map_scale), vmax=max(map_scale), **kwargs)\n",
    "        except: \n",
    "            self.ax = gdf.plot(ax=self.ax, cmap=colormap, **kwargs)\n",
    "\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def add_colorbar(\n",
    "        self,\n",
    "        cmap,\n",
    "        vmin,\n",
    "        vmax,\n",
    "        location=\"right\",\n",
    "        size=\"5%\",\n",
    "        pad=0.1,\n",
    "        alpha=1,\n",
    "        labelsize=16,\n",
    "        tickparams=None,\n",
    "    ):\n",
    "        \"\"\"Add custom colorbar to Map.\n",
    "\n",
    "        Needed since GeoPandas legend and plot axes do not align, see:\n",
    "        https://geopandas.readthedocs.io/en/latest/docs/user_guide/mapping.html\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cmap: Matplotlib colormap object or string reference (e.g. \"viridis\").\n",
    "        vmin: Minimum value of range colorbar.\n",
    "        vmax: Maximum value of range colorbar.\n",
    "        location: String for location of colorbar: \"top\", \"bottom\", \"left\"\n",
    "            or \"right\".\n",
    "        size: Size in either string percentage or number of pixels.\n",
    "        pad: Float for padding between the plot's frame and colorbar.\n",
    "        alpha: Float for alpha to apply to colorbar.\n",
    "        labelsize: Integer value for the text size of the ticklabels.\n",
    "        tickparams: Dictionary containing value-label pairs. For example:\n",
    "            {0.05: \"5%\", 0.1: \"10%\"}\n",
    "        \"\"\"\n",
    "        norm = plt.Normalize(vmin, vmax)\n",
    "        if isinstance(cmap, str):\n",
    "            cmap = plt.get_cmap(cmap)\n",
    "        cmap = color.force_alpha_colormap(cmap=cmap, alpha=alpha)\n",
    "        scalar_to_rgba = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        divider = make_axes_locatable(self.ax)\n",
    "        self.cax = divider.append_axes(location, size, pad)\n",
    "        self.cax.tick_params(labelsize=labelsize)\n",
    "        tickvalues = (\n",
    "            list(tickparams.keys()) if tickparams is not None else None\n",
    "        )\n",
    "        self.cbar = plt.colorbar(\n",
    "            scalar_to_rgba, cax=self.cax, ticks=tickvalues\n",
    "        )\n",
    "        if tickparams is not None:\n",
    "            self.cbar.set_ticklabels(list(tickparams.values()))\n",
    "        return self\n",
    "    \n",
    "    def save(\n",
    "        self, path, dpi=200, **kwargs\n",
    "    ):  # Just some defaults to reduce work.\n",
    "        \"\"\"Save Map figure to file.\n",
    "        Parameters\n",
    "        ----------\n",
    "        path: String path, e.g. \"./example.png\".\n",
    "        dpi: Integer dots per inch. Increase for higher resolution figures.\n",
    "        **kwargs: Matplotlib `savefig` keyword arguments.\n",
    "        \"\"\"\n",
    "        self.fig.savefig(path, dpi=dpi, bbox_inches=\"tight\", **kwargs)\n",
    "        plt.close(self.fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3242b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vid2date(i):\n",
    "    year=str(ViewsMonth(i).year)\n",
    "    month=str(ViewsMonth(i).month)\n",
    "    return year+'/'+month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89ebbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [445, 447, 450, 468]\n",
    "allsteps = [1, 3, 6, 24]\n",
    "titles = [vid2date(i) for i in times]\n",
    "#note the zip function occured earlier\n",
    "standard_scale = [np.log1p(0),np.log1p(10), np.log1p(50), np.log1p(100), np.log1p(1000), np.log1p(10000)]\n",
    "standard_scale_labels = ['0','10', '50','100', '1000', '10000']\n",
    "\n",
    "small_scale=[np.log1p(0),np.log1p(10), np.log1p(50), np.log1p(100), np.log1p(500)]\n",
    "small_scale_labels = ['0','10', '50','100', '500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df63153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the gdf\n",
    "engine = sa.create_engine(source_db_path)\n",
    "gdf_base = gpd.GeoDataFrame.from_postgis(\n",
    "    \"SELECT id as country_id, in_africa, in_me, geom FROM prod.country\", \n",
    "    engine, \n",
    "    geom_col='geom'\n",
    ")\n",
    "gdf = gdf_base.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80339ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test partition maps, predictions, rolling\n",
    "times_steps = [1, 3]\n",
    "lastmonthwithdata = 444\n",
    "path = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/maps/cm_rolling/'\n",
    "\n",
    "model = ModelList[-1]\n",
    "\n",
    "gdf2 = gdf_base.copy()\n",
    "df = model['test_df_calibrated'].copy()\n",
    "df = df.join(gdf2.set_index(\"country_id\"))\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geom\")\n",
    "\n",
    "for step in times_steps:\n",
    "    for tshift in [0,3,6,9,12,15,18,21,24,27,30,33,36,39,42,45]:\n",
    "        month = step + tshift + lastmonthwithdata\n",
    "        modelname = model['modelname']\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title='Model: '+ model['modelname'] + ', predictions as of ' + vid2date(lastmonthwithdata + tshift) + ', ' + str(step) + ' months ahead',\n",
    "        bbox=[-18.5, 64.0, -35.5, 43.0], \n",
    "        ).add_layer(\n",
    "        gdf=gdf.loc[month],\n",
    "        map_scale=standard_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "        column=f\"step_pred_{step}\", \n",
    "        inform_colorbar=True\n",
    "        )\n",
    "        m.cbar.set_ticks(standard_scale)\n",
    "        m.cbar.set_ticklabels(standard_scale_labels)\n",
    "\n",
    "        m.save(f'{path}cm_{modelname}_standard_scale_s{step}_t{tshift}_m{month}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2fe147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test partition maps, actuals\n",
    "lastmonthwithdata = 444\n",
    "path = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/maps/cm_actuals/'\n",
    "\n",
    "model = ModelList[-1]\n",
    "\n",
    "gdf2 = gdf_base.copy()\n",
    "df = model['test_df_calibrated'].copy()\n",
    "df = df.join(gdf2.set_index(\"country_id\"))\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geom\")\n",
    "\n",
    "for step in steps:\n",
    "    month = step + lastmonthwithdata\n",
    "    modelname = model['modelname']\n",
    "    m=Mapper2(\n",
    "    width=10,\n",
    "    height=10,\n",
    "    frame_on=True,\n",
    "    title='Actually recorded fatalities, month ' + vid2date(month),\n",
    "    bbox=[-18.5, 64.0, -35.5, 43.0], \n",
    "    ).add_layer(\n",
    "    gdf=gdf.loc[month],\n",
    "    map_scale=standard_scale,\n",
    "    cmap=\"rainbow\",\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.5,\n",
    "    column=f\"ln_ged_sb_dep\", \n",
    "    inform_colorbar=True\n",
    "    )\n",
    "    m.cbar.set_ticks(standard_scale)\n",
    "    m.cbar.set_ticklabels(standard_scale_labels)\n",
    "\n",
    "    m.save(f'{path}cm_actuals_standard_scale_s{step}_m{month}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
