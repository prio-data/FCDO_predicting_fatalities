{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5073ea7",
   "metadata": {},
   "source": [
    "# ViEWS 3 ensembles: future predictions\n",
    "UK FCDO Fatalities project, cm level\n",
    "\n",
    "This notebook produces future predictions for a set of models defined in the list of dictionaries ModelList and the weights stored as iweights_df.csv. Both of these are produced by the notebook fatal_cm_compute_ensemble in this repository. \n",
    "\n",
    "The notebook draws on the following .py script files in this repository:\n",
    "\n",
    "Ensembling.py\n",
    "\n",
    "FetchData.py\n",
    "\n",
    "HurdleRegression.py\n",
    "\n",
    "It also requires the list of models included in the ensemble, in the following file:\n",
    "\n",
    "EnsembleMetaData_cm_ + [run_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aedc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "import views_dataviz\n",
    "from views_runs import storage, ModelMetadata\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "from views_forecasts.extensions import *\n",
    "\n",
    "# Mapper\n",
    "import geopandas as gpd\n",
    "\n",
    "from views_dataviz.map import mapper, utils\n",
    "from views_dataviz import color\n",
    "from views_dataviz.map.presets import ViewsMap\n",
    "\n",
    "import sqlalchemy as sa\n",
    "#from ingester3.config import source_db_path\n",
    "\n",
    "# Other packages\n",
    "import pickle as pkl\n",
    "\n",
    "#Parallelization\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from functools import partial\n",
    "from genetic2 import *\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Predicting fatalities scripts\n",
    "from HurdleRegression import *\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "from FetchData import FetchData, RetrieveFromList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities001'\n",
    "run_id = 'Fatalities001' \n",
    "EndOfHistory = 508\n",
    "prod_id = '2022_04_t01'\n",
    "#run_id = dev_id + '_' + prod_id\n",
    "RunGeneticAlgo = False\n",
    "level = 'cm'\n",
    "WriteToOverleaf = True\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "#steps = [1,2,3,4,5,6,7,8,9,10,11,12,15,18,21,24] # Which steps to train and predict for\n",
    "#fi_steps = [1,3,6,12,36] # Which steps to present feature importances for\n",
    "#steps = [1,12,24,36]\n",
    "fi_steps = [1,3,6,12,36]\n",
    "#steps = [1,6,36]\n",
    "#fi_steps = [1,6,36]\n",
    "\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,444)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(445,492)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(493,504)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "# Specifying paths - note these have to be set to conform to individual setups!\n",
    "\n",
    "Mydropbox = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/'\n",
    "localgitpath = '/Users/havardhegre/views3/'\n",
    "\n",
    "if WriteToOverleaf:\n",
    "    overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2b744",
   "metadata": {},
   "source": [
    "# Retrieve models and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b242bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gitname = 'EnsembleMetaData_cm_' + dev_id + '.csv'\n",
    "EnsembleMetaData = pd.read_csv(gitname)\n",
    "ModelList = EnsembleMetaData.to_dict('records')\n",
    "i = 0\n",
    "for model in ModelList:\n",
    "    print(i, model['modelname'])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd7769",
   "metadata": {},
   "source": [
    "# Retrieve and calibrate predictions and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running and saving David's models\n",
    "# Import subprocess to run Rscript\n",
    "import subprocess\n",
    "\n",
    "# Fetch and save data (can perhaps be simplified?)\n",
    "qs = Queryset('hh_20_features','country_month')\n",
    "qs.fetch().to_parquet('markov/tmp.parquet')\n",
    "\n",
    "# Set commands and arguments. R-scripts located in 'Markov'-folder\n",
    "command ='Rscript'\n",
    "path2script ='markov/omm_ranger_hh20_fcdo_py.R'\n",
    "cmd = [command, path2script]\n",
    "data_path = localgitpath + 'FCDO_predicting_fatalities/markov/' + 'tmp.parquet'\n",
    "save_path = Mydropbox + 'Projects/PredictingFatalities/Predictions/cm/preds/'\n",
    "args = [str(EndOfHistory),data_path,save_path]\n",
    "\n",
    "# Run subprocess. Saves the predictions as csv-files to the save_path location with prefix vmm_[estimator]_hh20_[EndOfHistory]\n",
    "subprocess.call(cmd+args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72479321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve David's models from dropbox and store in prediction storage\n",
    "path = Mydropbox + 'Projects/PredictingFatalities/Predictions/cm/preds/'\n",
    "\n",
    "DRList = [\n",
    "    {\n",
    "        'modelname': 'fat_hh20_Markov_glm',\n",
    "        'filename': path + 'vmm_glm_hh20_' + str(EndOfHistory) + '.csv'\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        'modelname': 'fat_hh20_Markov_rf',\n",
    "        'filename': path + 'vmm_rf_hh20_' + str(EndOfHistory) + '.csv'\n",
    "    }\n",
    "]\n",
    "    \n",
    "for model in DRList:\n",
    "    df_future = pd.read_csv(model['filename'],index_col=['month_id','country_id'])\n",
    "    df_future['ln_ged_sb_dep'] = np.nan # Empty dependent variable column for consistency/required by prediction storage function\n",
    "    stored_modelname = level + '_' + model['modelname'] + '_f' + str(EndOfHistory)\n",
    "    df_future.forecasts.set_run(run_id)\n",
    "    df_future.forecasts.to_store(name=stored_modelname, overwrite=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "\n",
    "ModelList = RetrieveStoredPredictions(ModelList, steps, EndOfHistory, run_id)\n",
    "\n",
    "ModelList = CalibratePredictions(ModelList, EndOfHistory, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run querysets and postprocessing (e.g. PCA) to obtain data for future prediction\n",
    "# Returns as 'Datasets'; a list of dataframes\n",
    "Datasets = FetchData(dev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2428e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from views_runs import Storage, StepshiftedModels\n",
    "from views_partitioning.data_partitioner import DataPartitioner\n",
    "from viewser import Queryset, Column\n",
    "from views_runs import operations\n",
    "from views_runs.run_result import RunResult\n",
    "\n",
    "from pygam import LogisticGAM, LinearGAM, s, te\n",
    "\n",
    "RewritePredictions = True # Set this to True to rewrite predictions even if they exist\n",
    "\n",
    "def RetrainAndPredict(modelname):\n",
    "    force_retrain = False\n",
    "    modelstore = storage.Storage()\n",
    "    # Predictions for true future\n",
    "    ct = datetime.now()\n",
    "    print('Future', ct)\n",
    "    modelstore = storage.Storage()\n",
    "    model['RunResult_future']  = RunResult.retrain_or_retrieve(\n",
    "            retrain            = force_retrain,\n",
    "            store              = modelstore,\n",
    "            partitioner        = DataPartitioner({\"test\":future_partitioner_dict}),\n",
    "            stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "            dataset            = RetrieveFromList(Datasets,model['data_train']),\n",
    "            queryset_name      = model['queryset'],\n",
    "            partition_name     = \"test\",\n",
    "            timespan_name      = \"train\",\n",
    "            storage_name       = model['modelname'] + '_future',\n",
    "            author_name        = \"HH\",\n",
    "    )       \n",
    "    predictions_future = model['RunResult_future'].run.future_point_predict(EndOfHistory,model['RunResult_future'].data)\n",
    "    return predictions_future\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "print('Computing predictions, production run ' + prod_id + ', development run ' + run_id)\n",
    "for model in ModelList:\n",
    "\n",
    "    # Loop that checks whether (1) this a model trained outside the main system, \n",
    "    # (2) retrieves the prediction if it exists in prediction storage,\n",
    "    # (3) if not checks whether the trained model exists, retrains if not, \n",
    "    # Then calibrates the predictions and stores them if they have not been stored before for this run.\n",
    "    # To do: set the data_preprocessing to the function in the model dictionary\n",
    "    \n",
    "    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_noncalibrated' + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_cal'] = level +  '_' + model['modelname'] + '_calibrated' + '_f' + str(EndOfHistory)\n",
    "\n",
    "    \n",
    "    if 'Markov' not in model['modelname']: # Only Markov models are currently exceptions\n",
    "        print(i, model['modelname'])\n",
    "\n",
    "        ct = datetime.now()\n",
    "        print('Trying to retrieve non-calibrated predictions', ct)\n",
    "        if RewritePredictions:\n",
    "            model['future_df_noncalibrated'] = RetrainAndPredict(model['predstorename_ncal'])\n",
    "        else:\n",
    "            try:\n",
    "                model['future_df_noncalibrated'] = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstorename_ncal'])\n",
    "                print('Predictions for ', model['predstorename_ncal'], ', run', run_id, 'exist, retrieving from prediction storage')\n",
    "\n",
    "            except KeyError:\n",
    "                print(model['predstorename_ncal'], ', run', run_id, 'does not exist, predicting')\n",
    "                model['future_df_noncalibrated'] = RetrainAndPredict(model['predstorename_ncal'])\n",
    "\n",
    "        # Calibrating and storing   \n",
    "        # Storing non-calibrated\n",
    "        \n",
    "        model['future_df_noncalibrated'].forecasts.set_run(run_id)\n",
    "        model['future_df_noncalibrated'].forecasts.to_store(name=model['predstorename_ncal'], overwrite=True)   \n",
    "        print('Calibrating')\n",
    "        model['future_df_calibrated'] = model['future_df_noncalibrated'].copy()\n",
    "        for step in steps:\n",
    "            thismonth = EndOfHistory + step\n",
    "            \n",
    "            model['future_df_calibrated'].loc[thismonth,'step_combined'] = pd.DataFrame(model['calibration_gams'][step-1]['calibration_GAM'].predict(model['future_df_noncalibrated'].loc[thismonth])).values\n",
    "         # Storing calibrated\n",
    "        model['future_df_calibrated'].forecasts.set_run(run_id)\n",
    "        model['future_df_calibrated'].forecasts.to_store(name=model['predstorename_cal'], overwrite=True)   \n",
    "            \n",
    "    else: # If one of David's Markov models\n",
    "        print(i, model['modelname'])\n",
    "            \n",
    "        model['predstorename_noncalibrated'] = level +  '_' + model['modelname'] + '_noncalibrated' + '_f' + str(EndOfHistory)\n",
    "        print(model['predstorename_noncalibrated'], ', run', run_id, 'is being retrieved from dropbox')\n",
    "        path = Mydropbox + 'Projects/PredictingFatalities/Predictions/cm/preds/'\n",
    "\n",
    "        if model['modelname'] == 'fat_hh20_Markov_glm':\n",
    "            DR_filename = path + 'vmm_glm_hh20_' + str(EndOfHistory) + '.csv'\n",
    "            model['future_df_calibrated'] = pd.read_csv(DR_filename,index_col=['month_id','country_id'])\n",
    "        if model['modelname'] == 'fat_hh20_Markov_rf':\n",
    "            DR_filename = path + 'vmm_rf_hh20_' + str(EndOfHistory) + '.csv'\n",
    "            model['future_df_calibrated'] = pd.read_csv(DR_filename,index_col=['month_id','country_id'])\n",
    "            \n",
    "        model['predstorename_cal'] = level +  '_' + model['modelname'] + '_calibrated' + '_f' + str(EndOfHistory)\n",
    "\n",
    "        model['future_df_calibrated'].forecasts.set_run(run_id)\n",
    "        model['future_df_calibrated'].forecasts.to_store(name=model['predstorename_cal'], overwrite=True)   \n",
    "\n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "print('All done')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = RetrieveFromList(Datasets,model['data_train'])\n",
    "model['data_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e91e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnsembleList = [] # Separate list of dictionaries for ensembles!\n",
    "\n",
    "Ensemble = {\n",
    "    'modelname':            'genetic_ensemble',\n",
    "    'algorithm':            [],\n",
    "    'depvar':               'ln_ged_sb_dep',\n",
    "    'data_train':           [],\n",
    "    'Algorithm_text':       '',\n",
    "    'calibration_gams':     [],\n",
    "    'future_df_calibrated': [],\n",
    "}\n",
    "EnsembleList.append(Ensemble)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665beed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting in one df, one column per model\n",
    "ConstituentModels_df = pd.DataFrame(ModelList[0]['future_df_calibrated']['step_combined'])\n",
    "ConstituentModels_df.columns = [ModelList[0]['modelname']]\n",
    "for model in ModelList[1:]:\n",
    "    ConstituentModels_df[model['modelname']] = pd.DataFrame(model['future_df_calibrated']['step_combined'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc56996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve genetic algorithm results\n",
    "i_weights_df = pd.read_csv('GeneticWeights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fa49c",
   "metadata": {},
   "source": [
    "# Retrieve ensemble predictions for test partition to create categorical predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c6fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_modelname_test = level + '_' + 'ensemble_genetic' + '_test'\n",
    "\n",
    "ensemble_test_df = pd.DataFrame.forecasts.read_store(stored_modelname_test, run=run_id)\n",
    "ensemble_test_df.replace([np.inf, -np.inf], 0, inplace=True)  \n",
    "\n",
    "ensemble_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dichotomous version of dependent variable\n",
    "ensemble_test_df['ged_gte_25'] = ensemble_test_df['ln_ged_sb_dep'].apply(lambda x: 1 if x >= np.log1p(25) else 0)\n",
    "# Generate multiclass version for uncertainty estimation\n",
    "def ged_categorical(x):\n",
    "    if x < np.log1p(0.5):\n",
    "        return 0\n",
    "    elif x < np.log1p(10):\n",
    "        return 1\n",
    "    elif x < np.log1p(100):\n",
    "        return 2\n",
    "    elif x < np.log1p(1000):\n",
    "        return 3\n",
    "    else :\n",
    "        return 4\n",
    "\n",
    "ensemble_test_df['ged_multi'] = ensemble_test_df['ln_ged_sb_dep'].apply(ged_categorical)\n",
    "\n",
    "ensemble_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10eac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ensemble_test_df['ln_ged_sb_dep'],ensemble_test_df['ged_multi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model to transform predictions from  fatalities to (1) dichotomous and (2) multiclass\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "dichotomous_classifiers = []\n",
    "multi_classifiers = []\n",
    "for step in steps:\n",
    "    X = np.array(ensemble_test_df[f'step_pred_{step}'])\n",
    "    X = X.reshape(-1,1)\n",
    "    # Dichotomous\n",
    "    y_dich = np.array(ensemble_test_df['ged_gte_25']).reshape(-1, 1)\n",
    "    dich_clf = LogisticRegression(random_state=0).fit(X, y_dich)\n",
    "    dichotomous_classifiers.append(dich_clf)\n",
    "    p_dich = dich_clf.predict_proba(X)\n",
    "    ensemble_test_df['dich_step_{step}_logit'] = p_dich[:,1].ravel()\n",
    "    # Multiclass\n",
    "    y_multi = np.array(ensemble_test_df['ged_multi']).reshape(-1, 1)\n",
    "    multi_clf = LogisticRegression(random_state=0).fit(X, y_multi)\n",
    "    multi_classifiers.append(multi_clf)\n",
    "    p_multi = multi_clf.predict_proba(X)\n",
    "    for cls in [0,1,2,3,4]:\n",
    "        ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
    "\n",
    "ensemble_test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3650a01",
   "metadata": {},
   "source": [
    "# Calculating and storing ensemble future predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a placeholder df for ensemble predictions\n",
    "EnsembleList[0]['future_df_calibrated'] = ModelList[0]['future_df_calibrated'].copy() # Copy from baseline\n",
    "EnsembleList[0]['future_df_dichotomous'] = ModelList[0]['future_df_calibrated'].copy() # Copy from baseline\n",
    "\n",
    "ConstituentModels_df_w = ConstituentModels_df.copy()\n",
    "\n",
    "for step in steps:\n",
    "    month = EndOfHistory + step\n",
    "    weightcol = 'step_pred_' + str(step)\n",
    "    weights = np.array(pd.DataFrame(i_weights_df[weightcol]))\n",
    "    EnsembleList[0]['future_df_calibrated'].loc[month] = ConstituentModels_df_w.loc[month].dot(weights).values\n",
    "    x_d = np.array(EnsembleList[0]['future_df_calibrated'].loc[month]).reshape(-1,1)\n",
    "    pred_step = dichotomous_classifiers[step-1].predict_proba(x_d)\n",
    "    EnsembleList[0]['future_df_dichotomous']['step_combined'].loc[month] = pred_step[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58984a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the ensemble future predictions\n",
    "predstore_future = level +  '_' + EnsembleList[0]['modelname'] + '_f' + str(EndOfHistory)\n",
    "EnsembleList[0]['future_df_calibrated'].forecasts.set_run(run_id)\n",
    "EnsembleList[0]['future_df_calibrated'].forecasts.to_store(name=predstore_future, overwrite = True) \n",
    "predstore_future_dich = level +  '_' + EnsembleList[0]['modelname'] + '_dich_f' + str(EndOfHistory)\n",
    "EnsembleList[0]['future_df_dichotomous'].forecasts.set_run(run_id)\n",
    "EnsembleList[0]['future_df_dichotomous'].forecasts.to_store(name=predstore_future_dich, overwrite = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e86dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ViewsMetadata().with_name('genetic').fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16559555",
   "metadata": {},
   "source": [
    "# Mapping future predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470903a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import contextily as ctx\n",
    "\n",
    "from views_dataviz import color\n",
    "from views_dataviz.map import utils\n",
    "from views_dataviz.map.presets import ViewsMap\n",
    "\n",
    "import sqlalchemy as sa\n",
    "#from ingester3.config import source_db_path\n",
    "#from ingester3.Country import Country\n",
    "#from ingester3.extensions import *\n",
    "#from ingester3.ViewsMonth import ViewsMonth\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Mapper2:\n",
    "    \"\"\"\n",
    "    `Map` takes basic properties and allows the user to consecutively add\n",
    "    layers to the Map object. This makes it possible to prepare mapping\n",
    "    \"presets\" at any level of layeredness that can be built on further.\n",
    "    \n",
    "    Mapper2 allows for the customizable addition of scaling to the map. \n",
    "    -re-add the code for labels later when i can test it\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    width: Integer value for width in inches.\n",
    "    height: Integer value for height in inches.\n",
    "    bbox: List for the bbox per [xmin, xmax, ymin, ymax].\n",
    "    frame_on: Bool for whether to draw a frame around the map.\n",
    "    title: Optional default title at matplotlib's default size.\n",
    "    figure: Optional tuple of (fig, size) to use if you want to plot into an\n",
    "        already existing fig and ax, rather than making a new one.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        width,\n",
    "        height,\n",
    "        bbox=None,\n",
    "        cmap=None,\n",
    "        frame_on=True,\n",
    "        title=\"\",  # Default title without customization. (?)\n",
    "        figure=None,\n",
    "    ):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.bbox = bbox  # xmin, xmax, ymin, ymax\n",
    "        self.cmap = cmap\n",
    "        if figure is None:\n",
    "            self.fig, self.ax = plt.subplots(figsize=(self.width, self.height))\n",
    "        else:\n",
    "            self.fig, self.ax = figure\n",
    "        self.texts = []\n",
    "        self.ax.set_title(title)\n",
    "\n",
    "        if frame_on:  # Remove axis ticks only.\n",
    "            self.ax.tick_params(\n",
    "                top=False,\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                right=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=False,\n",
    "            )\n",
    "        else:\n",
    "            self.ax.axis(\"off\")\n",
    "\n",
    "        if bbox is not None:\n",
    "            self.ax.set_xlim((self.bbox[0], self.bbox[1]))\n",
    "            self.ax.set_ylim((self.bbox[2], self.bbox[3]))\n",
    "\n",
    "    def add_layer(self, gdf, map_scale=False, map_dictionary=False, cmap=None, inform_colorbar=False, **kwargs):\n",
    "        \"\"\"Add a geopandas plot to a new layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        gdf: Geopandas GeoDataFrame to plot.\n",
    "        cmap: Optional matplotlib colormap object or string reference\n",
    "            (e.g. \"viridis\").\n",
    "        inform_colorbar: Set or overwrite colorbar with the current layer.\n",
    "            Not applicable when `color` is supplied in the kwargs.\n",
    "        map_scale: set a manual scale for the map. If missing defaults to the Remco procedure. \n",
    "        map_dictionary: set manual labels for the map. If missing defaults to the default labels.\n",
    "        **kwargs: Geopandas `.plot` keyword arguments.\n",
    "        \"\"\"\n",
    "        if \"color\" in kwargs:\n",
    "            colormap = None\n",
    "        else:\n",
    "            colormap = self.cmap if cmap is None else cmap\n",
    "            if inform_colorbar and \"column\" in kwargs:\n",
    "                if hasattr(self, \"cax\"):\n",
    "                    self.cax.remove()\n",
    "                if \"vmin\" not in kwargs:\n",
    "                    self.vmin = gdf[kwargs[\"column\"]].min()\n",
    "                else:\n",
    "                    self.vmin = kwargs[\"vmin\"]\n",
    "                if \"vmax\" not in kwargs:\n",
    "                    self.vmax = gdf[kwargs[\"column\"]].max()\n",
    "                else:\n",
    "                    self.vmax = kwargs[\"vmax\"]\n",
    "        \n",
    "        try: Mapper2.add_colorbar(self, colormap, min(map_scale), max(map_scale))\n",
    "        except: Mapper2.add_colorbar(self, colormap, self.vmin, self.vmax)\n",
    "        \n",
    "        try:\n",
    "            self.ax = gdf.plot(ax=self.ax, cmap=colormap, vmin=min(map_scale), vmax=max(map_scale), **kwargs)\n",
    "        except: \n",
    "            self.ax = gdf.plot(ax=self.ax, cmap=colormap, **kwargs)\n",
    "\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def add_colorbar(\n",
    "        self,\n",
    "        cmap,\n",
    "        vmin,\n",
    "        vmax,\n",
    "        location=\"right\",\n",
    "        size=\"5%\",\n",
    "        pad=0.1,\n",
    "        alpha=1,\n",
    "        labelsize=16,\n",
    "        tickparams=None,\n",
    "    ):\n",
    "        \"\"\"Add custom colorbar to Map.\n",
    "\n",
    "        Needed since GeoPandas legend and plot axes do not align, see:\n",
    "        https://geopandas.readthedocs.io/en/latest/docs/user_guide/mapping.html\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cmap: Matplotlib colormap object or string reference (e.g. \"viridis\").\n",
    "        vmin: Minimum value of range colorbar.\n",
    "        vmax: Maximum value of range colorbar.\n",
    "        location: String for location of colorbar: \"top\", \"bottom\", \"left\"\n",
    "            or \"right\".\n",
    "        size: Size in either string percentage or number of pixels.\n",
    "        pad: Float for padding between the plot's frame and colorbar.\n",
    "        alpha: Float for alpha to apply to colorbar.\n",
    "        labelsize: Integer value for the text size of the ticklabels.\n",
    "        tickparams: Dictionary containing value-label pairs. For example:\n",
    "            {0.05: \"5%\", 0.1: \"10%\"}\n",
    "        \"\"\"\n",
    "        norm = plt.Normalize(vmin, vmax)\n",
    "        if isinstance(cmap, str):\n",
    "            cmap = plt.get_cmap(cmap)\n",
    "        cmap = color.force_alpha_colormap(cmap=cmap, alpha=alpha)\n",
    "        scalar_to_rgba = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        divider = make_axes_locatable(self.ax)\n",
    "        self.cax = divider.append_axes(location, size, pad)\n",
    "        self.cax.tick_params(labelsize=labelsize)\n",
    "        tickvalues = (\n",
    "            list(tickparams.keys()) if tickparams is not None else None\n",
    "        )\n",
    "        self.cbar = plt.colorbar(\n",
    "            scalar_to_rgba, cax=self.cax, ticks=tickvalues\n",
    "        )\n",
    "        if tickparams is not None:\n",
    "            self.cbar.set_ticklabels(list(tickparams.values()))\n",
    "        return self\n",
    "    \n",
    "    def save(\n",
    "        self, path, dpi=200, **kwargs\n",
    "    ):  # Just some defaults to reduce work.\n",
    "        \"\"\"Save Map figure to file.\n",
    "        Parameters\n",
    "        ----------\n",
    "        path: String path, e.g. \"./example.png\".\n",
    "        dpi: Integer dots per inch. Increase for higher resolution figures.\n",
    "        **kwargs: Matplotlib `savefig` keyword arguments.\n",
    "        \"\"\"\n",
    "        self.fig.savefig(path, dpi=dpi, bbox_inches=\"tight\", **kwargs)\n",
    "        plt.close(self.fig)\n",
    "        \n",
    "def vid2date(i):\n",
    "    year=str(1980 + i//12)\n",
    "    month=str(i%12)\n",
    "    return year+'/'+month\n",
    "        \n",
    "#def vid2date(i):\n",
    "#    year=str(ViewsMonth(i).year)\n",
    "#    month=str(ViewsMonth(i).month)\n",
    "#    return year+'/'+month\n",
    "\n",
    "#note the zip function occured earlier\n",
    "standard_scale = [np.log1p(0),np.log1p(3),np.log1p(10), np.log1p(30), np.log1p(100),  np.log1p(300), np.log1p(1000), np.log1p(3000),  np.log1p(10000)]\n",
    "standard_scale_labels = ['0', '3','10', '30','100', '300', '1000', '3000', '10000']\n",
    "\n",
    "small_scale=[np.log1p(0),np.log1p(3),np.log1p(10), np.log1p(30), np.log1p(100),  np.log1p(300), np.log1p(1000)]\n",
    "\n",
    "\n",
    "small_scale_labels = ['0', '3','10', '30','100', '300', '1000']\n",
    "\n",
    "small_scale_nolabels = ['', '','', '','', '', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the gdf\n",
    "gdf_base = gpd.read_parquet('./geometry/cm_geometry.parquet')\n",
    "gdf = gdf_base.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future prediction maps, predictions, rolling\n",
    "path = Mydropbox + 'Projects/PredictingFatalities/maps/cm_future/'\n",
    "stepstoplot=[3,5,8,12,24,36]\n",
    "#titles = [vid2date(i) for i in stepstoplot + EndOfHistory]\n",
    "\n",
    "\n",
    "df = EnsembleList[0]['future_df_calibrated'].copy()\n",
    "gdf2 = gdf_base.copy()\n",
    "df = df.join(gdf2.set_index(\"country_id\"))\n",
    "gdf3 = gpd.GeoDataFrame(df, geometry=\"geom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in stepstoplot:\n",
    "        month = step + EndOfHistory\n",
    "        gdf = gdf3.loc[month]\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title='Ensemble predictions as of ' + vid2date(EndOfHistory+step) + ', ' + str(step) + ' months after last month with data',\n",
    "        bbox=[-18.5, 64.0, -35.5, 43.0], \n",
    "        ).add_layer(\n",
    "        gdf=gdf,\n",
    "        map_scale=standard_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "        column='step_combined', \n",
    "        inform_colorbar=True\n",
    "        )\n",
    "        m.cbar.set_ticks(standard_scale)\n",
    "        m.cbar.set_ticklabels(standard_scale_labels)\n",
    "        if WriteToOverleaf:\n",
    "            m.save(f'{overleafpath}Figures/Future/PredictionMap_cm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')\n",
    "#        except:\n",
    "#            print('Overleaf/dropbox folder not found')\n",
    "        m.save(f'{path}PredictionMap_cm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7959a3",
   "metadata": {},
   "source": [
    "# Line graphs for individual countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CumulativeFatalities(df,steps):\n",
    "    ''' Calculates the sum of (real-space) fatalities in the step_combined column '''\n",
    "    # Loop over all steps \n",
    "    df['exp']=np.rint(np.expm1(df['step_combined'][0:steps+1]))\n",
    "    return df['exp'].sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "#ModelSelection = [1,3,5,9,11]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 6)\n",
    "path = Mydropbox + 'Projects/PredictingFatalities/PredictionPlots/cm_future/'\n",
    "\n",
    "log_scale_value = np.array([np.log1p(0), np.log1p(1), np.log1p(3), np.log1p(10), np.log1p(30), np.log1p(100),np.log1p(300),np.log1p(1000),np.log1p(3000)])\n",
    "log_scale_naming = ['0','1','3','10','30','100','300','1000','3000']\n",
    "month_value = np.arange(EndOfHistory+1, EndOfHistory+36, 3).tolist()\n",
    "month_name = []\n",
    "for m in month_value:\n",
    "    month_name.append(vid2date(m))\n",
    "\n",
    "first_month = EndOfHistory\n",
    "\n",
    "CountryList = [\n",
    "    ('Algeria',67,5000),\n",
    "    ('Angola',165,500),\n",
    "    ('Bahrain',127,500),\n",
    "    ('Benin',74,500),\n",
    "    ('Botswana',154,500),\n",
    "    ('Burkina Faso',47,2000),\n",
    "    ('Burundi',155,2000),\n",
    "    ('Cameroon',69,2000),\n",
    "    ('Central African Republic',70,2000),\n",
    "    ('Chad',214,2000),\n",
    "    ('Congo',166,2000),\n",
    "    ('Cote d\\'Ivoire',41,2000),\n",
    "    ('Djibouti',55,500),\n",
    "    ('DRCongo',167,20000),\n",
    "    ('Egypt',222,5000),\n",
    "    ('Equatorial Guinea',76,2000),\n",
    "    ('Eritrea',56,500),\n",
    "    ('Eswatini',164,500),\n",
    "    ('Ethiopia',57,2000),\n",
    "    ('Gabon',169,500),\n",
    "    ('The Gambia',54,500),\n",
    "    ('Ghana',42,500),\n",
    "    ('Guinea',48,500),\n",
    "    ('Guinea-Bissau',49,500),\n",
    "    ('Iran',128,2000),\n",
    "    ('Iraq',60,2000),\n",
    "    ('Israel',218,2000),\n",
    "    ('Jordan',62,2000),\n",
    "    ('Kenya',237,2000),\n",
    "    ('Lebanon',94,2000),\n",
    "    ('Lesotho',160,2000),\n",
    "    ('Liberia',43,2000),\n",
    "    ('Libya',213,5000),\n",
    "    ('Madagascar',172,500),\n",
    "    ('Malawi',161,2000),\n",
    "    ('Mali',50,20000),\n",
    "    ('Mauritania',244,500),\n",
    "    ('Morocco',243,500),\n",
    "    ('Mozambique',162,2000),\n",
    "    ('Namibia',170,500),\n",
    "    ('Niger',78,2000),\n",
    "    ('Nigeria',79,20000),\n",
    "    ('Oman',119,2000),\n",
    "    ('Qatar',130,2000),\n",
    "    ('Rwanda',156,2000),\n",
    "    ('Saudi Arabia',131,500),\n",
    "    ('Senegal',52,500),\n",
    "    ('Sierra Leone',53,500),\n",
    "    ('Somalia',120,20000),\n",
    "    ('South Africa',163,2000),\n",
    "    ('South Sudan',246,5000),\n",
    "    ('Sudan',245,2000),\n",
    "    ('Syria',220,50000),\n",
    "    ('Tanzania',242,500),\n",
    "    ('Togo',81,500),\n",
    "    ('Turkey',96,2000),\n",
    "    ('Uganda',235,2000),\n",
    "    ('United Arab Emirates',132,500),\n",
    "    ('Yemen',124,20000),\n",
    "    ('Zambia',157,2000),\n",
    "    ('Zimbabwe',158,5000),\n",
    "]\n",
    "\n",
    "\n",
    "df = EnsembleList[0]['future_df_calibrated'].copy()\n",
    "totals36 = []\n",
    "totals12 = []\n",
    "totals6 = []\n",
    "totals3 = []\n",
    "totals = []\n",
    "\n",
    "model = EnsembleList[-1]\n",
    "\n",
    "print(model['modelname'])\n",
    "# Calculate non-logged and cumulative series\n",
    "for cnt in CountryList:\n",
    "    plt.clf()\n",
    "#        print(cnt)\n",
    "    sc_df = EnsembleList[0]['future_df_calibrated'].xs(cnt[1],level=1)\n",
    "    print(cnt[0], '3 months: ', \"{:.0f}\".format(CumulativeFatalities(sc_df,3)), '12 months: ', \"{:.0f}\".format(CumulativeFatalities(sc_df,12)), ', 36 months:' \"{:.0f}\".format(CumulativeFatalities(sc_df,36)))\n",
    "    totals36.append({'Country': cnt[0], 'Fatalities': CumulativeFatalities(sc_df,36)})\n",
    "    totals12.append({'Country': cnt[0], 'Fatalities': CumulativeFatalities(sc_df,12)})\n",
    "    totals6.append({'Country': cnt[0], 'Fatalities': CumulativeFatalities(sc_df,6)})\n",
    "    totals3.append({'Country': cnt[0], 'Fatalities': CumulativeFatalities(sc_df,3)})\n",
    "    t = []\n",
    "    t.append({'Country': cnt[0], 'Fatalities': CumulativeFatalities(sc_df,36)})\n",
    "    t.append({'Country': cnt[0], 'Fatalities': CumulativeFatalities(sc_df,12)})\n",
    "    t.append({'Country': cnt[0], 'Fatalities': CumulativeFatalities(sc_df,6)})\n",
    "    t.append({'Country': cnt[0], 'Fatalities': CumulativeFatalities(sc_df,3)})\n",
    "    totals.append(t)\n",
    "    months = sc_df.index.to_series()\n",
    "    sc_df_exp = sc_df.copy()\n",
    "    plt.plot(months, 'step_combined', data=sc_df)\n",
    "    plt.suptitle('Forecasted number of fatalities, ' + cnt[0], fontsize=16)\n",
    "    plt.title('Total for 36-month period from ' + vid2date(EndOfHistory+1) + ' to ' + vid2date(EndOfHistory+36) +': ' +  \"{:.0f}\".format(CumulativeFatalities(sc_df,36)), fontsize=12)\n",
    "    plt.ylabel('Number of fatalities')\n",
    "    plt.yticks(log_scale_value, log_scale_naming, rotation=30)\n",
    "    plt.xticks(month_value, month_name, rotation=30)\n",
    "    plt.grid(axis='y')\n",
    "    plt.ylim([0,np.log1p(3000)])\n",
    "    filename = path + 'LineGraph_' + model['modelname'] + '_' + cnt[0] + '_r' + str(EndOfHistory) + '.png'\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    if cnt[0] == 'Ethiopia' or cnt[0] == 'Nigeria' or cnt[0] == 'DRCongo' or cnt[0] == 'Somalia' or cnt[0] == 'Yemen' or cnt[0] == 'Syria':\n",
    "        if WriteToOverleaf:\n",
    "            filename = overleafpath + 'Figures/Future/LineGraph_' + model['modelname'] + '_' + cnt[0] + '_r' + str(EndOfHistory) + '.png'\n",
    "            plt.savefig(filename, dpi=300)\n",
    "        \n",
    "# Collecting five top countries in one graph\n",
    "plt.clf()\n",
    "for cnt in CountryList:\n",
    "    if cnt[0] == 'Nigeria' or cnt[0] == 'DRCongo' or cnt[0] == 'Somalia' or cnt[0] == 'Yemen' or cnt[0] == 'Syria':\n",
    "        sc_df = EnsembleList[0]['future_df_calibrated'].xs(cnt[1],level=1)\n",
    "        months = sc_df.index.to_series()\n",
    "        sc_df_exp = sc_df.copy()\n",
    "        plt.plot(months, 'step_combined', data=sc_df, label = cnt[0])\n",
    "plt.suptitle('Forecasted number of fatalities, five most violent countries', fontsize=16)\n",
    "plt.ylabel('Number of fatalities')\n",
    "plt.yticks(log_scale_value, log_scale_naming, rotation=30)\n",
    "plt.xticks(month_value, month_name, rotation=30)\n",
    "plt.grid(axis='y')\n",
    "plt.ylim([0,np.log1p(3000)])\n",
    "plt.legend()\n",
    "filename = path + 'LineGraph_' + model['modelname'] + '_' + 'Top5' + '_r' + str(EndOfHistory) + '.png'\n",
    "plt.savefig(filename, dpi=300)\n",
    "if WriteToOverleaf:\n",
    "    filename = overleafpath + 'Figures/Future/LineGraph_' + model['modelname'] + '_' + 'Top5' + '_r' + str(EndOfHistory) + '.png'\n",
    "    plt.savefig(filename, dpi=300)\n",
    "\n",
    "totals36_df = pd.DataFrame(totals36)\n",
    "totals36_df['Fatalities'] = totals36_df['Fatalities'].astype(int)\n",
    "totals12_df = pd.DataFrame(totals12)\n",
    "totals12_df['Fatalities'] = totals12_df['Fatalities'].astype(int)\n",
    "totals6_df = pd.DataFrame(totals6)\n",
    "totals6_df['Fatalities'] = totals6_df['Fatalities'].astype(int)\n",
    "totals3_df = pd.DataFrame(totals3)\n",
    "totals3_df['Fatalities'] = totals3_df['Fatalities'].astype(int)\n",
    "totals_df = pd.DataFrame(totals)\n",
    "#totals12_df['Fatalities'] = totals12_df['Fatalities'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart for total predicted fatalities over next 36 months\n",
    "MinimumFatalities = [100,300]\n",
    "\n",
    "totals3_subset = totals3_df.loc[(totals3_df['Fatalities'] >= MinimumFatalities[0])]\n",
    "labels3 = totals3_subset['Country']\n",
    "sizes3 = totals3_subset['Fatalities']\n",
    "\n",
    "\n",
    "totals6_subset = totals6_df.loc[(totals6_df['Fatalities'] >= MinimumFatalities[0])]\n",
    "labels6 = totals6_subset['Country']\n",
    "sizes6 = totals6_subset['Fatalities']\n",
    "\n",
    "\n",
    "totals12_subset = totals12_df.loc[(totals12_df['Fatalities'] >= MinimumFatalities[0])]\n",
    "labels12 = totals12_subset['Country']\n",
    "sizes12 = totals12_subset['Fatalities']\n",
    "\n",
    "totals36_subset = totals36_df.loc[(totals36_df['Fatalities'] >= MinimumFatalities[0])]\n",
    "labels36 = totals36_subset['Country']\n",
    "sizes36 = totals36_subset['Fatalities']\n",
    "\n",
    "# Figure for 12 and 36 months into the future\n",
    "\n",
    "fig1,(ax1,ax2) = plt.subplots(1,2,figsize=(15,15))\n",
    "\n",
    "ax1.pie(sizes12, labels=labels12, autopct='%1.1f%%', shadow=False, startangle=110, radius=5000)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "ax2.pie(sizes36, labels=labels36, autopct='%1.1f%%', shadow=False, startangle=110)\n",
    "ax2.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "\n",
    "plt.title('Distribution of predicted fatalities, countries with more than ' + str(MinimumFatalities) + ' deaths')\n",
    "\n",
    "filename = path + 'TotalsPie_12_36_' + model['modelname'] + '_' + str(EndOfHistory) + '.png'\n",
    "plt.savefig(filename, dpi=300)\n",
    "if WriteToOverleaf:\n",
    "    filename = overleafpath + 'Figures/Future/TotalsPie_12_36_' + model['modelname'] + '_' + str(EndOfHistory) + '.png'\n",
    "    plt.savefig(filename, dpi=300)\n",
    "\n",
    "# Figure for 3 and 6 months\n",
    "fig2,(ax1,ax2) = plt.subplots(1,2,figsize=(15,15))\n",
    "\n",
    "ax1.pie(sizes3, labels=labels3, autopct='%1.1f%%', shadow=False, startangle=110, radius=5000)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "ax2.pie(sizes6, labels=labels6, autopct='%1.1f%%', shadow=False, startangle=110)\n",
    "ax2.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "\n",
    "plt.title('Distribution of predicted fatalities, countries with more than ' + str(MinimumFatalities) + ' deaths')\n",
    "\n",
    "filename = path + 'TotalsPie_3_6_' + model['modelname'] + '_' + str(EndOfHistory) + '.png'\n",
    "plt.savefig(filename, dpi=300)\n",
    "if WriteToOverleaf:\n",
    "    filename = overleafpath + 'Figures/Future/TotalsPie_3_6_' + model['modelname'] + '_' + str(EndOfHistory) + '.png'\n",
    "    plt.savefig(filename, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart, fatalities next 3/6/12/36 months\n",
    "labels3 = totals3_df['Country']\n",
    "sizes3 = totals3_df['Fatalities']\n",
    "\n",
    "labels6 = totals6_df['Country']\n",
    "sizes6 = totals6_df['Fatalities']\n",
    "\n",
    "labels12 = totals12_df['Country']\n",
    "sizes12 = totals12_df['Fatalities']\n",
    "\n",
    "labels36 = totals36_df['Country']\n",
    "sizes36 = totals36_df['Fatalities']\n",
    "\n",
    "# Figure for 12, 36 months into the future\n",
    "\n",
    "fig1,(ax1,ax2) = plt.subplots(1,2,figsize=(15,15))\n",
    "\n",
    "ax1.barh(width=sizes12, y=labels12)\n",
    "ax1.invert_yaxis()  # labels read top-to-bottom\n",
    "ax1.grid(axis = 'x')\n",
    "ax2.barh(width=sizes36, y=labels36)\n",
    "ax2.invert_yaxis()  # labels read top-to-bottom\n",
    "ax2.grid(axis = 'x')\n",
    "\n",
    "ax1.set_title('Total predicted fatalities, next 12 months')\n",
    "ax2.set_title('Total predicted fatalities, next 36 months')\n",
    "\n",
    "#plt.title('Predicted fatalities')\n",
    "\n",
    "filename = path + 'TotalsBar_12_36_' + model['modelname'] + '_' + str(EndOfHistory) + '.png'\n",
    "plt.savefig(filename, dpi=300)\n",
    "if WriteToOverleaf:\n",
    "    filename = overleafpath + 'Figures/Future/TotalsBar_12_36_' + model['modelname'] + '_' + str(EndOfHistory) + '.png'\n",
    "    plt.savefig(filename, dpi=300)\n",
    "\n",
    "# Figure for 3, 6 months into the future\n",
    "\n",
    "fig1,(ax1,ax2) = plt.subplots(1,2,figsize=(15,15))\n",
    "\n",
    "ax1.barh(width=sizes3, y=labels3)\n",
    "ax1.invert_yaxis()  # labels read top-to-bottom\n",
    "ax1.grid(axis = 'x')\n",
    "ax2.barh(width=sizes6, y=labels6)\n",
    "ax2.invert_yaxis()  # labels read top-to-bottom\n",
    "ax2.grid(axis = 'x')\n",
    "\n",
    "ax1.set_title('Total predicted fatalities, next 3 months')\n",
    "ax2.set_title('Total predicted fatalities, next 6 months')\n",
    "\n",
    "#plt.title('Predicted fatalities')\n",
    "\n",
    "filename = path + 'TotalsBar_3_6_' + model['modelname'] + '_' + str(EndOfHistory) + '.png'\n",
    "plt.savefig(filename, dpi=300)\n",
    "if WriteToOverleaf:\n",
    "    filename = overleafpath + 'Figures/Future/TotalsBar_3_6_' + model['modelname'] + '_' + str(EndOfHistory) + '.png'\n",
    "    plt.savefig(filename, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f6f05d",
   "metadata": {},
   "source": [
    "## Retrain the surrogate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb44e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets[10]['df']['vdem_v2x_libdem'].loc[544]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1beef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cm_surrogatemodels import TrainSurrogateModels\n",
    "SurrogateModelSteps = [1,3,6,36]\n",
    "SurrogateModelSteps = steps\n",
    "EndOfHistory_test = test_partitioner_dict['train'][1] \n",
    "Plotpath = Mydropbox + 'Projects/PredictingFatalities/SurrogateModels/'\n",
    "\n",
    "\n",
    "       \n",
    "SurrogateModelList = TrainSurrogateModels(data_df = Datasets[10]['df'], \n",
    "                                          Ensemble_df = ensemble_test_df, \n",
    "                                          EndOfHistory = EndOfHistory_test, \n",
    "                                          SurrogateModelSteps = SurrogateModelSteps, \n",
    "                                          NumberOfMonths = 48,\n",
    "                                          Plotpath = Plotpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41164a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_df = Datasets[10]['df'].loc[EndOfHistory]\n",
    "\n",
    "EnsembleList[0]['future_df_surrogates'] = EnsembleList[0]['future_df_calibrated'].copy()\n",
    "# Initialize dataframe to hold surrogate model predictions:\n",
    "for item in SurrogateModelList:\n",
    "    if item['Step'] == 1:\n",
    "        colname = item['Modelname'][item['Modelname'].index(' ') + 1:] # Remove first word (which is a step number)\n",
    "        EnsembleList[0]['future_df_surrogates'][colname] = np.nan  \n",
    "# Compute predictions for each step\n",
    "for step in steps:\n",
    "    month = EndOfHistory + step\n",
    "#    print('Step',step,'Month',month)\n",
    "    for item in SurrogateModelList:\n",
    "        colname = item['Modelname'][item['Modelname'].index(' ') + 1:] # Remove first word (which is a step number)\n",
    "        if item['Step']==step:\n",
    "#            print('colname:',colname,'Step:',item['Step'], item['Columns'])\n",
    "            EnsembleList[0]['future_df_surrogates'][colname].loc[month] = item['GAM'].predict(predictors_df[item['Columns']])\n",
    "\n",
    "# Storing the surrogate model future predictions\n",
    "for item in SurrogateModelList:\n",
    "    if item['Step'] == 36:\n",
    "        colname = item['Modelname'][item['Modelname'].index(' ') + 1:] # Remove first word (which is a step number)\n",
    "        predstore_future = level +  '_surrogate_' + item['Shortname'] + '_f' + str(EndOfHistory)\n",
    "        print('Storing surrogate model predictions for model',colname, 'as:',predstore_future)\n",
    "        predictions_to_store = pd.DataFrame(EnsembleList[0]['future_df_surrogates'][colname])\n",
    "        predictions_to_store.forecasts.set_run(run_id)\n",
    "        predictions_to_store.forecasts.to_store(name=predstore_future, overwrite = True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662636ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mapping\n",
    "\n",
    "predictors_df = Datasets[10]['df'].loc[EndOfHistory]\n",
    "predictors_df_3m = Datasets[10]['df'].loc[EndOfHistory-3]\n",
    "\n",
    "path = Mydropbox + 'Projects/PredictingFatalities/maps/cm_future/Surrogate/'\n",
    "surrogate_scale=[np.log1p(0),np.log1p(3),np.log1p(10), np.log1p(30), np.log1p(100), np.log1p(300)]\n",
    "\n",
    "surrogate_scale_labels = ['', '','', '', '', '']\n",
    "\n",
    "MapSteps = [1,3,6,12,36]\n",
    "for model in SurrogateModelList:\n",
    "    if model['Step'] in MapSteps:\n",
    "        print(model['Modelname'], model['Columns'])\n",
    "\n",
    "        df = predictors_df[model['Columns']]\n",
    "        df[model['Predcolname']] = model['GAM'].predict(predictors_df[model['Columns']])\n",
    "        gdf2 = gdf_base.copy()\n",
    "        df = df.join(gdf2.set_index(\"country_id\"))\n",
    "        gdf3 = gpd.GeoDataFrame(df, geometry=\"geom\")\n",
    "        Predcolname = model['Predcolname']\n",
    "        step = model['Step']\n",
    "        TargetMonth = EndOfHistory+step\n",
    "\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title='Surrogate model ' + model['Modelname'] + ' predictions as of ' + vid2date(TargetMonth) + ', ' + str(step) + ' months after last month with data',\n",
    "        bbox=[-18.5, 64.0, -35.5, 43.0], \n",
    "        ).add_layer(\n",
    "        gdf=gdf3,\n",
    "        map_scale=surrogate_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.5,\n",
    "        column=model['Predcolname'], \n",
    "        inform_colorbar=True\n",
    "        )\n",
    "        m.cbar.set_ticks(surrogate_scale)\n",
    "        m.cbar.set_ticklabels(surrogate_scale_labels)\n",
    "\n",
    "        m.save(f'{path}cm_surrogate_{Predcolname}_small_scale_{EndOfHistory}_{TargetMonth}.png')\n",
    "        if WriteToOverleaf:\n",
    "            m.save(f'{overleafpath}Figures/Future/cm_surrogate_{Predcolname}_small_scale_{EndOfHistory}_{TargetMonth}.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99aa1a",
   "metadata": {},
   "source": [
    "# Changes to 3- and 6-month forecasts, and since last actual observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data for mapping\n",
    "# Predictions now and then\n",
    "predstore_then = level +  '_' + EnsembleList[0]['modelname'] + '_f' + str(EndOfHistory-3)\n",
    "\n",
    "df_now = EnsembleList[0]['future_df_calibrated'].copy()\n",
    "try:\n",
    "    df_then = pd.DataFrame.forecasts.read_store(run=run_id, name=predstore_then)\n",
    "except:\n",
    "    print('Trouble reading forecasts issued three months ago')\n",
    "    \n",
    "# Actuals\n",
    "qs = (Queryset(\"hh_fatalities_ged_ln_ultrashort\", \"country_month\"))\n",
    "df_lastobserved = qs.fetch().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28adbdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log of mean non-logged fatalities, past six months\n",
    "df_observed = df_lastobserved.loc[EndOfHistory]\n",
    "df_observed['ged_sb_0'] = np.expm1(df_observed['ln_ged_sb'])\n",
    "df_observed['ged_sum'] = df_observed['ged_sb_0']\n",
    "for t in [1,2,3,4,5]:\n",
    "    colname = 'ged_sb_' + str(t)\n",
    "    df_observed[colname] = np.expm1(df_lastobserved.loc[EndOfHistory-t]['ln_ged_sb'])\n",
    "    df_observed['ged_sum'] = df_observed['ged_sum'] + df_observed[colname]\n",
    "df_observed['ln_ged_sum'] = np.log1p(df_observed['ged_sum']/6)\n",
    "#df_observed.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa84aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepsForward = [\n",
    "{\n",
    "    'Step': 3,\n",
    "    'df_now': df_now.loc[EndOfHistory + 3],\n",
    "    'df_then': df_then.loc[EndOfHistory - 3 + 3]\n",
    "},\n",
    "{\n",
    "    'Step': 6,\n",
    "    'df_now': df_now.loc[EndOfHistory + 6],\n",
    "    'df_then': df_then.loc[EndOfHistory - 3 + 6]\n",
    "},\n",
    "    {\n",
    "    'Step': 12,\n",
    "    'df_now': df_now.loc[EndOfHistory + 12],\n",
    "    'df_then': df_then.loc[EndOfHistory - 3 + 12]\n",
    "},\n",
    "    {\n",
    "    'Step': 36,\n",
    "    'df_now': df_now.loc[EndOfHistory + 36],\n",
    "    'df_then': df_then.loc[EndOfHistory - 3 + 36]\n",
    "},\n",
    "]\n",
    "engine = sa.create_engine(source_db_path)\n",
    "#predictors_df = data_vdem_short.loc[EndOfHistory]\n",
    "#predictors_df_3m = data_vdem_short.loc[EndOfHistory-3]\n",
    "\n",
    "for s in StepsForward:\n",
    "    s['df_now'].rename(columns={'step_combined':'Now'}, inplace=True)\n",
    "    s['df_then'].rename(columns={'step_combined':'Then'}, inplace=True)\n",
    "    s['df'] = pd.concat([s['df_now'],s['df_then'],df_observed['ln_ged_sum']],axis=1)\n",
    "    s['df']['Change_in_prediction'] = s['df']['Now']-s['df']['Then']\n",
    "    s['df']['Change_since_last_observed'] = s['df']['Now']-s['df']['ln_ged_sum']\n",
    "    \n",
    "    # Surrogate model change\n",
    "    for sm in SurrogateModelList:\n",
    "        if sm['Step'] == s['Step']:\n",
    "            s['sdf'] = predictors_df[sm['Columns']]\n",
    "            s['sdf'][sm['Predcolname']] = sm['GAM'].predict(predictors_df[sm['Columns']])\n",
    "            s['sdf_3m'] = predictors_df_3m[sm['Columns']]\n",
    "            s['sdf_3m'][sm['Predcolname']] = sm['GAM'].predict(predictors_df_3m[sm['Columns']])\n",
    "            print(sm['Step'],sm['Predcolname'])\n",
    "            dfcolname = sm['Predcolname'][:-2] + '_ch3m'\n",
    "            s['df'][dfcolname] = s['sdf'][sm['Predcolname']] - s['sdf_3m'][sm['Predcolname']]\n",
    "    \n",
    "    s['gdf'] = gpd.GeoDataFrame.from_postgis(\n",
    "        \"SELECT id as country_id, in_africa, in_me, geom FROM prod.country\", \n",
    "        engine, \n",
    "        geom_col='geom'\n",
    "    )\n",
    "    s['gdf'] = s['gdf'].to_crs(4326)\n",
    "\n",
    "    s['gdf_t'] = s['df'].join(s['gdf'].set_index(\"country_id\"))\n",
    "    s['gdf'] = gpd.GeoDataFrame(s['gdf_t'], geometry=\"geom\")\n",
    "    \n",
    "    \n",
    "StepsForward[1]['gdf'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe165d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 3\n",
    "\n",
    "tickvalues=np.array([-300,-30,-3,3,30,300])\n",
    "ticklabels=[str(tv) for tv in tickvalues]\n",
    "\n",
    "tickvalues=np.sign(tickvalues)*np.log1p(np.abs(tickvalues)+1)\n",
    "#print(tickvalues)\n",
    "tickvalues = np.array([-83,-80,-50,-20,0,20,50,100,200,500])\n",
    "ticklabels=[str(tv) for tv in tickvalues]\n",
    "ticklabels[0] = \"\"\n",
    "tickvalues = np.log((100+tickvalues)/100)\n",
    "\n",
    "\n",
    "t0s=range(506,508) # From start of month A, to start of (but not including) month B\n",
    "bbox=\"africa_middle_east\"\n",
    "cmap='bwr'#'rainbow'\n",
    "ColumnsToPlot = ['Change_in_prediction',\n",
    "                 'Change_since_last_observed',\n",
    "                 's_pred_mCH_ch3m',\n",
    "                 's_pred_mNCH_ch3m',\n",
    "                 's_pred_mDem_ch3m',\n",
    "                 's_pred_mIMR_ch3m',\n",
    "                # 's_pred_mTopics10_ch3m',\n",
    "                ]\n",
    "\n",
    "\n",
    "for s in StepsForward:\n",
    "    print('Step:',s['Step'])\n",
    "    for column in ColumnsToPlot:\n",
    "        titlestring=''\n",
    "        plot = ViewsMap(\n",
    "            width=10,\n",
    "            label=f\"{column}, s= {s['Step']}\",\n",
    "            title=\"\",\n",
    "            scale=None,\n",
    "            bbox=bbox\n",
    "        ).add_layer(\n",
    "            s['gdf'],\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.2,\n",
    "            column=column,\n",
    "        inform_colorbar=True,\n",
    "        cmap=cmap,\n",
    "        vmin=tickvalues[0],vmax=tickvalues[-1]\n",
    "    )\n",
    "\n",
    "        ax=plot.ax\n",
    "        fg=s['gdf'].plot(ax=ax,edgecolor='black',linewidth=0.2,facecolor='None')\n",
    "       # fg=gdf_c.plot(ax=ax,edgecolor='gray',linewidth=1.0,facecolor='None')\n",
    "        figure=plot.fig\n",
    "        fontdict={'fontsize':20}\n",
    "        fig=plot.fig\n",
    "\n",
    "        plot.cbar.set_ticks(tickvalues)\n",
    "        plot.cbar.set_ticklabels(ticklabels)\n",
    "        if abs(delta)==1:\n",
    "            mnth='month'\n",
    "        else:\n",
    "            mnth='months'\n",
    "        plot.cbar.set_label(f'Percent change in {column} over past '+str(delta)+' '+mnth)\n",
    "        plot.save(path+column+str(s['Step'])+'_r' + str(EndOfHistory) +'.png')\n",
    "        if WriteToOverleaf:\n",
    "            plot.save(overleafpath+'Figures/Future/'+column+str(s['Step'])+'_r' + str(EndOfHistory) +'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5043ad",
   "metadata": {},
   "source": [
    "# Uncertainty of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a61fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model to transform predictions from  fatalities to multiclass probabilities\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "multi_classifiers = []\n",
    "df_future = EnsembleList[0]['future_df_calibrated'].copy()\n",
    "for cls in [0,1,2,3,4]:\n",
    "    df_future[f'multi_{cls}_logit'] = np.nan\n",
    "\n",
    "for step in steps:\n",
    "    Month = EndOfHistory + step\n",
    "    X = np.array(ensemble_test_df[f'step_pred_{step}'])\n",
    "    X = X.reshape(-1,1)\n",
    "    # Multiclass\n",
    "    y_multi = np.array(ensemble_test_df['ged_multi']).reshape(-1, 1)\n",
    "    multi_clf = LogisticRegression(random_state=0).fit(X, y_multi)\n",
    "    multi_classifiers.append(multi_clf)\n",
    "    X_future = np.array(df_future['step_combined'].loc[Month]).reshape(-1,1)\n",
    "    p_multi = multi_clf.predict_proba(X_future)\n",
    "    for cls in [0,1,2,3,4]:\n",
    "        df_future[f'multi_{cls}_logit'].loc[Month] = p_multi[:,cls]\n",
    "\n",
    "        \n",
    "df_future.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c522ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future.to_csv('Categorical_probabilities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e09da4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
