{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27b8652",
   "metadata": {},
   "source": [
    "# ViEWS 3 ensembles: future predictions\n",
    "\n",
    "UK FCDO Fatalities project, pgm level\n",
    "\n",
    "This notebook produces future predictions for a set of models defined in the list of dictionaries ModelList, produced by the notebook fatal_pgm_compute_ensemble in this repository. \n",
    "\n",
    "The notebook draws on the following .py script files in this repository:\n",
    "\n",
    "Ensembling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf471b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3c1351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refreshing\n"
     ]
    }
   ],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "import views_dataviz\n",
    "from views_runs import storage, ModelMetadata\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "from views_forecasts.extensions import *\n",
    "\n",
    "# Mapper\n",
    "import geopandas as gpd\n",
    "\n",
    "from views_dataviz.map import mapper, utils\n",
    "from views_dataviz import color\n",
    "from views_dataviz.map.presets import ViewsMap\n",
    "\n",
    "import sqlalchemy as sa\n",
    "#from ingester3.config import source_db_path\n",
    "\n",
    "# Other packages\n",
    "import pickle as pkl\n",
    "\n",
    "#Parallelization\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "from functools import partial\n",
    "from genetic2 import *\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Predicting fatalities scripts\n",
    "from HurdleRegression import *\n",
    "import Ensembling\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "import FetchData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ec2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities001'\n",
    "run_id = 'Fatalities001' \n",
    "EndOfHistory = 507\n",
    "prod_id = 'Prod_' + str(EndOfHistory) + '_v1' # Change to run_id + str(EndOfHistory) + 'v1'\n",
    "get_future = True\n",
    "\n",
    "level = 'pgm'\n",
    "\n",
    "depvar = \"ln_ged_sb_dep\"\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "#steps = [1,2,3,4,5,6,7,8,9,10,11,12,15,18,21,24] # Which steps to train and predict for\n",
    "#fi_steps = [1,3,6,12,36] # Which steps to present feature importances for\n",
    "#steps = [1,12,24,36]\n",
    "fi_steps = [1,3,6,12,36]\n",
    "#steps = [1,6,36]\n",
    "#fi_steps = [1,6,36]\n",
    "\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,444)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(445,492)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(493,504)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = '/Users/jim/Dropbox (ViEWS)/ViEWS/'\n",
    "\n",
    "overleafpath = '/Users/jim/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70052d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fat_jed_hh_baseline_lgbm\n",
      "1 fat_jed_hh_conflictlong_lgbm\n",
      "2 fat_jed_hh_conflictlong_hurdle_lgbm\n",
      "3 fat_jed_hh_drought_hurdle_lgbm\n",
      "4 fat_jed_hh_drought_lgbm\n",
      "5 fat_jed_hh_natsoc_hurdle_lgbm\n",
      "6 fat_jed_hh_natsoc_lgbm\n",
      "7 fat_jed_hh_broad_hurdle_lgbm\n",
      "8 fat_jed_hh_broad_lgbm\n",
      "9 fat_jed_pv_conf_hist_pgm\n",
      "10 fat_tree_lags_d_1_d_2_hur_36\n",
      "11 fat_sptime_dist_nu1_10_001_hur_36\n"
     ]
    }
   ],
   "source": [
    "gitname = 'EnsembleMetaData_pgm_' + dev_id + '.csv'\n",
    "EnsembleMetaData = pd.read_csv(gitname)\n",
    "ModelList = EnsembleMetaData.to_dict('records')\n",
    "i = 0\n",
    "for model in ModelList:\n",
    "    print(i, model['modelname'])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f0a267",
   "metadata": {},
   "source": [
    "# Retrieve and calibrate predictions and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edabbed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fat_jed_hh_baseline_lgbm\n",
      "pr_45_pgm_fat_jed_hh_baseline_lgbm_calib.parquet\n",
      "pr_45_pgm_fat_jed_hh_baseline_lgbm_test.parquet\n",
      "1 fat_jed_hh_conflictlong_lgbm\n",
      "pr_45_pgm_fat_jed_hh_conflictlong_lgbm_calib.parquet\n",
      "pr_45_pgm_fat_jed_hh_conflictlong_lgbm_test.parquet\n",
      "2 fat_jed_hh_conflictlong_hurdle_lgbm\n",
      "pr_45_pgm_fat_jed_hh_conflictlong_hurdle_lgbm_calib.parquet\n",
      "pr_45_pgm_fat_jed_hh_conflictlong_hurdle_lgbm_test.parquet\n",
      "3 fat_jed_hh_drought_hurdle_lgbm\n",
      "pr_45_pgm_fat_jed_hh_drought_hurdle_lgbm_calib.parquet\n",
      "pr_45_pgm_fat_jed_hh_drought_hurdle_lgbm_test.parquet\n",
      "4 fat_jed_hh_drought_lgbm\n",
      "pr_45_pgm_fat_jed_hh_drought_lgbm_calib.parquet\n",
      "pr_45_pgm_fat_jed_hh_drought_lgbm_test.parquet\n",
      "5 fat_jed_hh_natsoc_hurdle_lgbm\n",
      "pr_45_pgm_fat_jed_hh_natsoc_hurdle_lgbm_calib.parquet\n",
      "pr_45_pgm_fat_jed_hh_natsoc_hurdle_lgbm_test.parquet\n",
      "6 fat_jed_hh_natsoc_lgbm\n",
      "pr_45_pgm_fat_jed_hh_natsoc_lgbm_calib.parquet\n",
      "pr_45_pgm_fat_jed_hh_natsoc_lgbm_test.parquet\n",
      "7 fat_jed_hh_broad_hurdle_lgbm\n",
      "pr_45_pgm_fat_jed_hh_broad_hurdle_lgbm_calib.parquet\n",
      "pr_45_pgm_fat_jed_hh_broad_hurdle_lgbm_test.parquet\n",
      "8 fat_jed_hh_broad_lgbm\n",
      "pr_45_pgm_fat_jed_hh_broad_lgbm_calib.parquet\n",
      "pr_45_pgm_fat_jed_hh_broad_lgbm_test.parquet\n",
      "9 fat_jed_pv_conf_hist_pgm\n",
      "pr_45_pgm_fat_jed_pv_conf_hist_pgm_calib.parquet\n",
      "pr_45_pgm_fat_jed_pv_conf_hist_pgm_test.parquet\n",
      "10 fat_tree_lags_d_1_d_2_hur_36\n",
      "pr_45_pgm_fat_tree_lags_d_1_d_2_hur_36_calib.parquet\n",
      "pr_45_pgm_fat_tree_lags_d_1_d_2_hur_36_test.parquet\n",
      "11 fat_sptime_dist_nu1_10_001_hur_36\n",
      "pr_45_pgm_fat_sptime_dist_nu1_10_001_hur_36_calib.parquet\n",
      "pr_45_pgm_fat_sptime_dist_nu1_10_001_hur_36_test.parquet\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "\n",
    "ModelList = Ensembling.RetrieveStoredPredictions_pgm(ModelList, steps, EndOfHistory, run_id, level, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45eb1a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data using querysets; returns as list of dictionaries containing datasets\n",
      " .    baseline: A dataset with 8 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    conflictlong: A dataset with 19 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    escwa_drought: A dataset with 29 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    natsoc: A dataset with 24 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    broad: A dataset with 23 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    paola_conf_hist: A dataset with 30 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    conf_treelag: A dataset with 8 columns, with data between t = 1 and 852; 13110 units.\n",
      " .    conf_sptime_dist: A dataset with 11 columns, with data between t = 1 and 852; 13110 units.\n"
     ]
    }
   ],
   "source": [
    "Datasets = FetchData.FetchData_pgm(dev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8651ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fat_jed_hh_baseline_lgbm\n",
      "LGBMRegressor(n_estimators=200)\n",
      "fat_jed_hh_conflictlong_lgbm\n",
      "LGBMRegressor(n_estimators=200)\n",
      "fat_jed_hh_conflictlong_hurdle_lgbm\n",
      "HurdleRegression(clf_name='LGBMClassifier', clf_params={'n_estimators': 200},\n",
      "                 reg_name='LGBMRegressor', reg_params={'n_estimators': 200})\n",
      "fat_jed_hh_drought_hurdle_lgbm\n",
      "HurdleRegression(clf_name='LGBMClassifier', clf_params={'n_estimators': 200},\n",
      "                 reg_name='LGBMRegressor', reg_params={'n_estimators': 200})\n",
      "fat_jed_hh_drought_lgbm\n",
      "LGBMRegressor(n_estimators=200)\n",
      "fat_jed_hh_natsoc_hurdle_lgbm\n",
      "HurdleRegression(clf_name='LGBMClassifier', clf_params={'n_estimators': 200},\n",
      "                 reg_name='LGBMRegressor', reg_params={'n_estimators': 200})\n",
      "fat_jed_hh_natsoc_lgbm\n",
      "LGBMRegressor(n_estimators=200)\n",
      "fat_jed_hh_broad_hurdle_lgbm\n",
      "HurdleRegression(clf_name='LGBMClassifier', clf_params={'n_estimators': 200},\n",
      "                 reg_name='LGBMRegressor', reg_params={'n_estimators': 200})\n",
      "fat_jed_hh_broad_lgbm\n",
      "LGBMRegressor(n_estimators=200)\n",
      "fat_jed_pv_conf_hist_pgm\n",
      "XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             enable_categorical=False, gamma=None, gpu_id=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=200, n_jobs=12, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=None, tree_method='hist',\n",
      "             validate_parameters=None, verbosity=None)\n",
      "fat_tree_lags_d_1_d_2_hur_36\n",
      "HurdleRegression(clf_name='XGBClassifier',\n",
      "                 clf_params={'n_estimators': 200, 'n_jobs': 12},\n",
      "                 reg_name='XGBRegressor',\n",
      "                 reg_params={'n_estimators': 200, 'n_jobs': 12})\n",
      "fat_sptime_dist_nu1_10_001_hur_36\n",
      "HurdleRegression(clf_name='XGBClassifier',\n",
      "                 clf_params={'n_estimators': 200, 'n_jobs': 12},\n",
      "                 reg_name='XGBRegressor',\n",
      "                 reg_params={'n_estimators': 200, 'n_jobs': 12})\n"
     ]
    }
   ],
   "source": [
    "for model in ModelList:\n",
    "    print(model['modelname'])\n",
    "    print(model['algorithm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62bffe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions, production run Prod_507_v1, development run Fatalities001\n",
      "0 fat_jed_hh_baseline_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 09:58:06.525415\n",
      "pgm_fat_jed_hh_baseline_lgbm_f507\n",
      "Future 2022-06-15 09:58:06.724564\n",
      " * == Performing a run: \"fat_jed_hh_baseline_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_baseline_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_baseline_lgbm_future\" from storage\n",
      "0 fat_jed_hh_baseline_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 09:58:45.222190\n",
      "Future 2022-06-15 09:58:45.331693\n",
      " * == Performing a run: \"fat_jed_hh_baseline_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_baseline_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_baseline_lgbm_future\" from storage\n",
      "1 fat_jed_hh_conflictlong_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 09:59:22.633212\n",
      "pgm_fat_jed_hh_conflictlong_lgbm_f507\n",
      "Future 2022-06-15 09:59:22.674771\n",
      " * == Performing a run: \"fat_jed_hh_conflictlong_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_conflictlong_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_conflictlong_lgbm_future\" from storage\n",
      "1 fat_jed_hh_conflictlong_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:00:01.210678\n",
      "Future 2022-06-15 10:00:01.263443\n",
      " * == Performing a run: \"fat_jed_hh_conflictlong_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_conflictlong_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_conflictlong_lgbm_future\" from storage\n",
      "2 fat_jed_hh_conflictlong_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:00:43.343431\n",
      "pgm_fat_jed_hh_conflictlong_hurdle_lgbm_f507\n",
      "Future 2022-06-15 10:00:43.377406\n",
      " * == Performing a run: \"fat_jed_hh_conflictlong_hurdle_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_conflictlong_hurdle_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_conflictlong_hurdle_lgbm_future\" from storage\n",
      "2 fat_jed_hh_conflictlong_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:01:50.255972\n",
      "Future 2022-06-15 10:01:50.301650\n",
      " * == Performing a run: \"fat_jed_hh_conflictlong_hurdle_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_conflictlong_hurdle_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_conflictlong_hurdle_lgbm_future\" from storage\n",
      "3 fat_jed_hh_drought_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:03:00.486638\n",
      "pgm_fat_jed_hh_drought_hurdle_lgbm_f507\n",
      "Future 2022-06-15 10:03:00.525235\n",
      " * == Performing a run: \"fat_jed_hh_drought_hurdle_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_drought_hurdle_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_drought_hurdle_lgbm_future\" from storage\n",
      "3 fat_jed_hh_drought_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:04:11.262317\n",
      "Future 2022-06-15 10:04:11.305992\n",
      " * == Performing a run: \"fat_jed_hh_drought_hurdle_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_drought_hurdle_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_drought_hurdle_lgbm_future\" from storage\n",
      "4 fat_jed_hh_drought_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:05:26.182574\n",
      "pgm_fat_jed_hh_drought_lgbm_f507\n",
      "Future 2022-06-15 10:05:26.226209\n",
      " * == Performing a run: \"fat_jed_hh_drought_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_drought_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_drought_lgbm_future\" from storage\n",
      "4 fat_jed_hh_drought_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:06:04.955706\n",
      "Future 2022-06-15 10:06:04.994853\n",
      " * == Performing a run: \"fat_jed_hh_drought_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_drought_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_drought_lgbm_future\" from storage\n",
      "5 fat_jed_hh_natsoc_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:06:48.034530\n",
      "pgm_fat_jed_hh_natsoc_hurdle_lgbm_f507\n",
      "Future 2022-06-15 10:06:48.076871\n",
      " * == Performing a run: \"fat_jed_hh_natsoc_hurdle_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_natsoc_hurdle_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_natsoc_hurdle_lgbm_future\" from storage\n",
      "5 fat_jed_hh_natsoc_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:08:01.755273\n",
      "Future 2022-06-15 10:08:01.801790\n",
      " * == Performing a run: \"fat_jed_hh_natsoc_hurdle_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_natsoc_hurdle_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_natsoc_hurdle_lgbm_future\" from storage\n",
      "6 fat_jed_hh_natsoc_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:09:18.030886\n",
      "pgm_fat_jed_hh_natsoc_lgbm_f507\n",
      "Future 2022-06-15 10:09:18.064849\n",
      " * == Performing a run: \"fat_jed_hh_natsoc_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_natsoc_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_natsoc_lgbm_future\" from storage\n",
      "6 fat_jed_hh_natsoc_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:09:59.335025\n",
      "Future 2022-06-15 10:09:59.374933\n",
      " * == Performing a run: \"fat_jed_hh_natsoc_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_natsoc_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_natsoc_lgbm_future\" from storage\n",
      "7 fat_jed_hh_broad_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:10:40.563419\n",
      "pgm_fat_jed_hh_broad_hurdle_lgbm_f507\n",
      "Future 2022-06-15 10:10:40.608439\n",
      " * == Performing a run: \"fat_jed_hh_broad_hurdle_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_broad_hurdle_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_broad_hurdle_lgbm_future\" from storage\n",
      "7 fat_jed_hh_broad_hurdle_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:11:53.864334\n",
      "Future 2022-06-15 10:11:53.902761\n",
      " * == Performing a run: \"fat_jed_hh_broad_hurdle_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_broad_hurdle_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_broad_hurdle_lgbm_future\" from storage\n",
      "8 fat_jed_hh_broad_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:13:07.112060\n",
      "pgm_fat_jed_hh_broad_lgbm_f507\n",
      "Future 2022-06-15 10:13:07.150671\n",
      " * == Performing a run: \"fat_jed_hh_broad_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_broad_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_broad_lgbm_future\" from storage\n",
      "8 fat_jed_hh_broad_lgbm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:13:45.693973\n",
      "Future 2022-06-15 10:13:45.731372\n",
      " * == Performing a run: \"fat_jed_hh_broad_lgbm_future\" == * \n",
      "Model object named \"fat_jed_hh_broad_lgbm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_hh_broad_lgbm_future\" from storage\n",
      "9 fat_jed_pv_conf_hist_pgm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:14:27.980627\n",
      "pgm_fat_jed_pv_conf_hist_pgm_f507\n",
      "Future 2022-06-15 10:14:28.016792\n",
      " * == Performing a run: \"fat_jed_pv_conf_hist_pgm_future\" == * \n",
      "Model object named \"fat_jed_pv_conf_hist_pgm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_pv_conf_hist_pgm_future\" from storage\n",
      "9 fat_jed_pv_conf_hist_pgm\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:15:02.473160\n",
      "Future 2022-06-15 10:15:02.516930\n",
      " * == Performing a run: \"fat_jed_pv_conf_hist_pgm_future\" == * \n",
      "Model object named \"fat_jed_pv_conf_hist_pgm_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_jed_pv_conf_hist_pgm_future\" from storage\n",
      "10 fat_tree_lags_d_1_d_2_hur_36\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:15:37.989597\n",
      "pgm_fat_tree_lags_d_1_d_2_hur_36_f507\n",
      "Future 2022-06-15 10:15:38.023843\n",
      " * == Performing a run: \"fat_tree_lags_d_1_d_2_hur_36_future\" == * \n",
      "Model object named \"fat_tree_lags_d_1_d_2_hur_36_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_tree_lags_d_1_d_2_hur_36_future\" from storage\n",
      "10 fat_tree_lags_d_1_d_2_hur_36\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:16:22.821432\n",
      "Future 2022-06-15 10:16:22.859825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * == Performing a run: \"fat_tree_lags_d_1_d_2_hur_36_future\" == * \n",
      "Model object named \"fat_tree_lags_d_1_d_2_hur_36_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_tree_lags_d_1_d_2_hur_36_future\" from storage\n",
      "11 fat_sptime_dist_nu1_10_001_hur_36\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:17:09.772475\n",
      "pgm_fat_sptime_dist_nu1_10_001_hur_36_f507\n",
      "Future 2022-06-15 10:17:09.813145\n",
      " * == Performing a run: \"fat_sptime_dist_nu1_10_001_hur_36_future\" == * \n",
      "Model object named \"fat_sptime_dist_nu1_10_001_hur_36_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_sptime_dist_nu1_10_001_hur_36_future\" from storage\n",
      "11 fat_sptime_dist_nu1_10_001_hur_36\n",
      "Trying to retrieve non-calibrated predictions 2022-06-15 10:17:55.887791\n",
      "Future 2022-06-15 10:17:55.927256\n",
      " * == Performing a run: \"fat_sptime_dist_nu1_10_001_hur_36_future\" == * \n",
      "Model object named \"fat_sptime_dist_nu1_10_001_hur_36_future\" with equivalent metadata already exists.\n",
      "Fetching \"fat_sptime_dist_nu1_10_001_hur_36_future\" from storage\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "calibrate_const_models=False\n",
    "\n",
    "from views_runs import Storage, StepshiftedModels\n",
    "from views_partitioning.data_partitioner import DataPartitioner\n",
    "from viewser import Queryset, Column\n",
    "from views_runs import operations\n",
    "from views_runs.run_result import RunResult\n",
    "\n",
    "RewritePredictions = True # Set this to True to rewrite predictions even if they exist\n",
    "\n",
    "def RetrainAndPredict(modelname):\n",
    "    force_retrain = False\n",
    "    modelstore = storage.Storage()\n",
    "    # Predictions for true future\n",
    "    ct = datetime.now()\n",
    "    print('Future', ct)\n",
    "    modelstore = storage.Storage()\n",
    "    model['RunResult_future']  = RunResult.retrain_or_retrieve(\n",
    "            retrain            = force_retrain,\n",
    "            store              = modelstore,\n",
    "            partitioner        = DataPartitioner({\"test\":future_partitioner_dict}),\n",
    "            stepshifted_models = StepshiftedModels(model['algorithm'], steps, model['depvar']),\n",
    "            dataset            = FetchData.get_training_data(Datasets,ModelList,modelname),\n",
    "            queryset_name      = model['queryset'],\n",
    "            partition_name     = \"test\",\n",
    "            timespan_name      = \"train\",\n",
    "            storage_name       = model['modelname'] + '_future',\n",
    "            author_name        = \"JED\",\n",
    "    )       \n",
    "    predictions_future = model['RunResult_future'].run.future_point_predict(EndOfHistory,model['RunResult_future'].data)\n",
    "    return predictions_future\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "print('Computing predictions, production run ' + prod_id + ', development run ' + run_id)\n",
    "for model in ModelList:\n",
    "\n",
    "    # Loop that checks whether (1) this a model trained outside the main system, \n",
    "    # (2) retrieves the prediction if it exists in prediction storage,\n",
    "    # (3) if not checks whether the trained model exists, retrains if not, \n",
    "    # Then calibrates the predictions and stores them if they have not been stored before for this run.\n",
    "    # To do: set the data_preprocessing to the function in the model dictionary\n",
    "    \n",
    "#    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_noncalibrated' + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_cal'] = level +  '_' + model['modelname'] + '_calibrated' + '_f' + str(EndOfHistory)\n",
    "\n",
    "    print(i, model['modelname'])\n",
    "\n",
    "    ct = datetime.now()\n",
    "    print('Trying to retrieve non-calibrated predictions', ct)\n",
    "    if RewritePredictions:\n",
    "        print(model['predstorename_ncal'])\n",
    "        model['future_df_noncalibrated'] = RetrainAndPredict(model['modelname'])\n",
    "    else:\n",
    "        try:\n",
    "            model['future_df_noncalibrated'] = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstorename_ncal'])\n",
    "            print('Predictions for ', model['predstorename_ncal'], ', run', run_id, 'exist, retrieving from prediction storage')\n",
    "\n",
    "        except KeyError:\n",
    "            print(model['predstorename_ncal'], ', run', run_id, 'does not exist, predicting')\n",
    "            model['future_df_noncalibrated'] = RetrainAndPredict(model['predstorename_ncal'])\n",
    "\n",
    "    # Calibrating and storing   \n",
    "    # Storing non-calibrated\n",
    "        \n",
    "#    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_noncalibrated' + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_ncal'] = level +  '_' + model['modelname'] + '_f' + str(EndOfHistory)\n",
    "    model['predstorename_cal'] = level +  '_' + model['modelname'] + '_calibrated' + '_f' + str(EndOfHistory)\n",
    "\n",
    "    print(i, model['modelname'])\n",
    "\n",
    "    ct = datetime.now()\n",
    "    print('Trying to retrieve non-calibrated predictions', ct)\n",
    "    if RewritePredictions:\n",
    "        model['future_df_noncalibrated'] = RetrainAndPredict(model['modelname'])\n",
    "    else:\n",
    "        try:\n",
    "            model['future_df_noncalibrated'] = pd.DataFrame.forecasts.read_store(run=run_id, name=model['predstorename_ncal'])\n",
    "            print('Predictions for ', model['predstorename_ncal'], ', run', run_id, 'exist, retrieving from prediction storage')\n",
    "\n",
    "        except KeyError:\n",
    "            print(model['predstorename_ncal'], ', run', run_id, 'does not exist, predicting')\n",
    "            model['future_df_noncalibrated'] = RetrainAndPredict(model['predstorename_ncal'])\n",
    "\n",
    "    # Calibrating and storing   \n",
    "    # Storing non-calibrated\n",
    "    \n",
    "#    print('before store',model['future_df_noncalibrated'].index.names)\n",
    "        \n",
    "    model['future_df_noncalibrated'].forecasts.set_run(run_id)\n",
    "    model['future_df_noncalibrated'].forecasts.to_store(name=model['predstorename_ncal'], overwrite=True)   \n",
    "    \n",
    "#    print('after store',model['future_df_noncalibrated'].index.names)\n",
    "    \n",
    "    if calibrate_const_models:\n",
    "        print('Calibrating')\n",
    "        model['future_df_calibrated'] = model['future_df_noncalibrated'].copy()\n",
    "            \n",
    "        model['future_df_calibrated']['step_combined']=cal_pg_c(model['future_df_calibrated'],cm_predictions_future,'step_combined',df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)    \n",
    "        # Storing calibrated\n",
    "        model['future_df_calibrated'].forecasts.set_run(run_id)\n",
    "        model['future_df_calibrated'].forecasts.to_store(name=model['predstorename_cal'], overwrite=True)   \n",
    "            \n",
    "    i = i + 1\n",
    "\n",
    "print('All done')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e78a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnsembleList = [] # Separate list of dictionaries for ensembles!\n",
    "\n",
    "Ensemble = {\n",
    "    'modelname':            'ensemble_cm_calib',\n",
    "    'algorithm':            [],\n",
    "    'depvar':               depvar,\n",
    "    'data_train':           [],\n",
    "    'Algorithm_text':       '',\n",
    "    'calibration_gams':     [],\n",
    "    'future_df_calibrated': [],\n",
    "}\n",
    "EnsembleList.append(Ensemble)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42948b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_ensemble=ViewsMetadata().with_name('cm_genetic_ensemble_f'+str(EndOfHistory)).fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3cc1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_run_id=int(cm_ensemble['runs_id'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa5e4645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_33_cm_ensemble_genetic_calib.parquet\n",
      "pr_33_cm_ensemble_genetic_test.parquet\n",
      "pr_33_cm_genetic_ensemble_f507.parquet\n"
     ]
    }
   ],
   "source": [
    "cm_predictions_calib = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_ensemble_genetic_calib')\n",
    "cm_predictions_test = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_ensemble_genetic_test')\n",
    "cm_predictions_future = pd.DataFrame.forecasts.read_store(run=calib_run_id, name='cm_genetic_ensemble_f'+str(EndOfHistory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61dd6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepcols=['step_pred_' + str(step) for step in steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b56c18c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding fat_jed_hh_conflictlong_lgbm\n",
      "adding fat_jed_hh_conflictlong_hurdle_lgbm\n",
      "adding fat_jed_hh_drought_hurdle_lgbm\n",
      "adding fat_jed_hh_drought_lgbm\n",
      "adding fat_jed_hh_natsoc_hurdle_lgbm\n",
      "adding fat_jed_hh_natsoc_lgbm\n",
      "adding fat_jed_hh_broad_hurdle_lgbm\n",
      "adding fat_jed_hh_broad_lgbm\n",
      "adding fat_jed_pv_conf_hist_pgm\n",
      "adding fat_tree_lags_d_1_d_2_hur_36\n",
      "adding fat_sptime_dist_nu1_10_001_hur_36\n",
      " .    "
     ]
    }
   ],
   "source": [
    "n_models = len(ModelList)\n",
    "\n",
    "targetcalib=ModelList[0]['predictions_calib_df'][depvar]\n",
    "targettest=ModelList[0]['predictions_test_df'][depvar]\n",
    "\n",
    "valscalib=ModelList[0]['predictions_calib_df'][stepcols].values.copy()\n",
    "valstest=ModelList[0]['predictions_test_df'][stepcols].values.copy()\n",
    "valsfuture=ModelList[0]['future_df_noncalibrated'].values.copy()\n",
    "\n",
    "trimmed_calib=ModelList[0]['predictions_calib_df'][stepcols].copy()\n",
    "index_calib=trimmed_calib.index\n",
    "columns_calib=trimmed_calib.columns\n",
    "\n",
    "trimmed_test=ModelList[0]['predictions_test_df'][stepcols].copy()\n",
    "index_test=trimmed_test.index\n",
    "columns_test=trimmed_test.columns\n",
    "\n",
    "trimmed_future=ModelList[0]['future_df_noncalibrated'].copy()\n",
    "index_future=trimmed_future.index\n",
    "columns_future=trimmed_future.columns\n",
    "\n",
    "for model in ModelList[1:]:\n",
    "    print('adding',model['modelname'])\n",
    "\n",
    "    valscalib+=model['predictions_calib_df'][stepcols].values.copy()\n",
    "    valstest+=model['predictions_test_df'][stepcols].values.copy()\n",
    "    valsfuture+=model['future_df_noncalibrated'].values.copy()\n",
    "\n",
    "    valscalib/=n_models\n",
    "    valstest/=n_models\n",
    "    valsfuture/=n_models\n",
    "\n",
    "    Ensemble['predictions_calib_df']=pd.DataFrame(data=valscalib, index=index_calib, columns=columns_calib)\n",
    "    Ensemble['predictions_test_df']=pd.DataFrame(data=valstest, index=index_test, columns=columns_test)\n",
    "    Ensemble['predictions_future_df']=pd.DataFrame(data=valsfuture, index=index_future, columns=columns_future)\n",
    "    \n",
    "df_pg_id_c_id=Ensembling.fetch_df_pg_id_c_id()\n",
    "    \n",
    "for col in stepcols:\n",
    "\n",
    "    thisstep=int(''.join([''+str(f) for f in filter(str.isdigit, col)]))\n",
    "    thismonth = EndOfHistory + thisstep\n",
    "\n",
    "    Ensemble['predictions_calib_df'][col]=Ensembling.calibrate_pg_with_c(Ensemble['predictions_calib_df'],cm_predictions_calib,col,df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)\n",
    "\n",
    "    Ensemble['predictions_test_df'][col]=Ensembling.calibrate_pg_with_c(Ensemble['predictions_test_df'],cm_predictions_test,col,df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)\n",
    "    \n",
    "future_calib=Ensembling.calibrate_pg_with_c(Ensemble['predictions_future_df'],cm_predictions_future,'step_combined',df_pg_id_c_id=df_pg_id_c_id,log_feature=True,super_calibrate=False)    \n",
    "    \n",
    "Ensemble['predictions_future_df']['step_combined']=future_calib['step_combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53e583c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble['predictions_calib_df'][depvar]=targetcalib\n",
    "Ensemble['predictions_test_df'][depvar]=targettest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08ccc4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble predictions\n",
    "predstore_calib = level +  '_' + Ensemble['modelname'] + '_calib'\n",
    "Ensemble['predictions_calib_df'].forecasts.set_run(run_id)\n",
    "Ensemble['predictions_calib_df'].forecasts.to_store(name=predstore_calib, overwrite = True)\n",
    "predstore_test = level +  '_' + Ensemble['modelname'] + '_test'\n",
    "Ensemble['predictions_test_df'].forecasts.set_run(run_id)\n",
    "Ensemble['predictions_test_df'].forecasts.to_store(name=predstore_test, overwrite = True)\n",
    "predstore_future = level +  '_' + Ensemble['modelname'] + '_f'+str(EndOfHistory)\n",
    "Ensemble['predictions_future_df'].forecasts.set_run(run_id)\n",
    "Ensemble['predictions_future_df'].forecasts.to_store(name=predstore_future, overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355ad4d",
   "metadata": {},
   "source": [
    "# Use ensemble predictions for test partition to create categorical predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48672578",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_df=Ensemble['predictions_test_df'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbba3611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_pred_1</th>\n",
       "      <th>step_pred_2</th>\n",
       "      <th>step_pred_3</th>\n",
       "      <th>step_pred_4</th>\n",
       "      <th>step_pred_5</th>\n",
       "      <th>step_pred_6</th>\n",
       "      <th>step_pred_7</th>\n",
       "      <th>step_pred_8</th>\n",
       "      <th>step_pred_9</th>\n",
       "      <th>step_pred_10</th>\n",
       "      <th>...</th>\n",
       "      <th>step_pred_30</th>\n",
       "      <th>step_pred_31</th>\n",
       "      <th>step_pred_32</th>\n",
       "      <th>step_pred_33</th>\n",
       "      <th>step_pred_34</th>\n",
       "      <th>step_pred_35</th>\n",
       "      <th>step_pred_36</th>\n",
       "      <th>ln_ged_sb_dep</th>\n",
       "      <th>ged_gte_25</th>\n",
       "      <th>ged_multi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.048460</td>\n",
       "      <td>0.050175</td>\n",
       "      <td>0.050129</td>\n",
       "      <td>0.050069</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.059946</td>\n",
       "      <td>0.061269</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.074190</td>\n",
       "      <td>0.065181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053682</td>\n",
       "      <td>0.054162</td>\n",
       "      <td>0.053358</td>\n",
       "      <td>0.051066</td>\n",
       "      <td>0.055259</td>\n",
       "      <td>0.053029</td>\n",
       "      <td>0.052785</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.279730</td>\n",
       "      <td>0.280987</td>\n",
       "      <td>0.277936</td>\n",
       "      <td>0.290519</td>\n",
       "      <td>0.276473</td>\n",
       "      <td>0.349047</td>\n",
       "      <td>0.345778</td>\n",
       "      <td>0.422694</td>\n",
       "      <td>0.448508</td>\n",
       "      <td>0.391891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275788</td>\n",
       "      <td>0.282272</td>\n",
       "      <td>0.280178</td>\n",
       "      <td>0.276111</td>\n",
       "      <td>0.290054</td>\n",
       "      <td>0.293955</td>\n",
       "      <td>0.280265</td>\n",
       "      <td>0.207899</td>\n",
       "      <td>0.034433</td>\n",
       "      <td>0.130805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.020138</td>\n",
       "      <td>-0.127007</td>\n",
       "      <td>-0.002590</td>\n",
       "      <td>-0.121167</td>\n",
       "      <td>-0.097833</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>-0.004704</td>\n",
       "      <td>-0.013511</td>\n",
       "      <td>-0.007174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133681</td>\n",
       "      <td>-0.005615</td>\n",
       "      <td>-0.006883</td>\n",
       "      <td>-0.013513</td>\n",
       "      <td>-0.390458</td>\n",
       "      <td>-0.014770</td>\n",
       "      <td>-0.013674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.005884</td>\n",
       "      <td>0.006388</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009109</td>\n",
       "      <td>0.009278</td>\n",
       "      <td>0.009206</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>0.009410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.269841</td>\n",
       "      <td>6.592434</td>\n",
       "      <td>7.232289</td>\n",
       "      <td>8.278019</td>\n",
       "      <td>7.849818</td>\n",
       "      <td>10.700899</td>\n",
       "      <td>9.918594</td>\n",
       "      <td>10.460919</td>\n",
       "      <td>10.240162</td>\n",
       "      <td>9.569431</td>\n",
       "      <td>...</td>\n",
       "      <td>7.613748</td>\n",
       "      <td>7.032987</td>\n",
       "      <td>6.759357</td>\n",
       "      <td>7.108057</td>\n",
       "      <td>7.265648</td>\n",
       "      <td>7.385541</td>\n",
       "      <td>7.027814</td>\n",
       "      <td>7.817223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step_pred_1    step_pred_2    step_pred_3    step_pred_4  \\\n",
       "count  629280.000000  629280.000000  629280.000000  629280.000000   \n",
       "mean        0.048460       0.050175       0.050129       0.050069   \n",
       "std         0.279730       0.280987       0.277936       0.290519   \n",
       "min        -0.020138      -0.127007      -0.002590      -0.121167   \n",
       "25%         0.000075       0.000106       0.000135       0.000143   \n",
       "50%         0.000430       0.000546       0.000625       0.000731   \n",
       "75%         0.002898       0.003392       0.003745       0.004117   \n",
       "max         7.269841       6.592434       7.232289       8.278019   \n",
       "\n",
       "         step_pred_5    step_pred_6    step_pred_7    step_pred_8  \\\n",
       "count  629280.000000  629280.000000  629280.000000  629280.000000   \n",
       "mean        0.049780       0.059946       0.061269       0.069110   \n",
       "std         0.276473       0.349047       0.345778       0.422694   \n",
       "min        -0.097833      -0.000500      -0.000435      -0.004704   \n",
       "25%         0.000182       0.000202       0.000218       0.000259   \n",
       "50%         0.000841       0.000894       0.000961       0.001091   \n",
       "75%         0.004504       0.004938       0.005522       0.005884   \n",
       "max         7.849818      10.700899       9.918594      10.460919   \n",
       "\n",
       "         step_pred_9   step_pred_10  ...   step_pred_30   step_pred_31  \\\n",
       "count  629280.000000  629280.000000  ...  629280.000000  629280.000000   \n",
       "mean        0.074190       0.065181  ...       0.053682       0.054162   \n",
       "std         0.448508       0.391891  ...       0.275788       0.282272   \n",
       "min        -0.013511      -0.007174  ...      -0.133681      -0.005615   \n",
       "25%         0.000295       0.000282  ...       0.000576       0.000558   \n",
       "50%         0.001205       0.001272  ...       0.002033       0.002049   \n",
       "75%         0.006388       0.006558  ...       0.009109       0.009278   \n",
       "max        10.240162       9.569431  ...       7.613748       7.032987   \n",
       "\n",
       "        step_pred_32   step_pred_33   step_pred_34   step_pred_35  \\\n",
       "count  629280.000000  629280.000000  629280.000000  629280.000000   \n",
       "mean        0.053358       0.051066       0.055259       0.053029   \n",
       "std         0.280178       0.276111       0.290054       0.293955   \n",
       "min        -0.006883      -0.013513      -0.390458      -0.014770   \n",
       "25%         0.000563       0.000622       0.000580       0.000614   \n",
       "50%         0.002026       0.002278       0.002167       0.002198   \n",
       "75%         0.009206       0.009563       0.009535       0.009273   \n",
       "max         6.759357       7.108057       7.265648       7.385541   \n",
       "\n",
       "        step_pred_36  ln_ged_sb_dep     ged_gte_25      ged_multi  \n",
       "count  629280.000000  629280.000000  629280.000000  629280.000000  \n",
       "mean        0.052785       0.016279       0.001187       0.010920  \n",
       "std         0.280265       0.207899       0.034433       0.130805  \n",
       "min        -0.013674       0.000000       0.000000       0.000000  \n",
       "25%         0.000571       0.000000       0.000000       0.000000  \n",
       "50%         0.002038       0.000000       0.000000       0.000000  \n",
       "75%         0.009410       0.000000       0.000000       0.000000  \n",
       "max         7.027814       7.817223       1.000000       4.000000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate dichotomous version of dependent variable\n",
    "ensemble_test_df['ged_gte_25'] = ensemble_test_df['ln_ged_sb_dep'].apply(lambda x: 1 if x >= np.log1p(25) else 0)\n",
    "# Generate multiclass version for uncertainty estimation\n",
    "def ged_categorical(x):\n",
    "    if x < np.log1p(0.5):\n",
    "        return 0\n",
    "    elif x < np.log1p(10):\n",
    "        return 1\n",
    "    elif x < np.log1p(100):\n",
    "        return 2\n",
    "    elif x < np.log1p(1000):\n",
    "        return 3\n",
    "    else :\n",
    "        return 4\n",
    "\n",
    "ensemble_test_df['ged_multi'] = ensemble_test_df['ln_ged_sb_dep'].apply(ged_categorical)\n",
    "\n",
    "ensemble_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b7a17d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d6464520>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(ensemble_test_df['ln_ged_sb_dep'],ensemble_test_df['ged_multi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93d86f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jim/opt/anaconda3/envs/viewser/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_85842/2360434821.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_pred_1</th>\n",
       "      <th>step_pred_2</th>\n",
       "      <th>step_pred_3</th>\n",
       "      <th>step_pred_4</th>\n",
       "      <th>step_pred_5</th>\n",
       "      <th>step_pred_6</th>\n",
       "      <th>step_pred_7</th>\n",
       "      <th>step_pred_8</th>\n",
       "      <th>step_pred_9</th>\n",
       "      <th>step_pred_10</th>\n",
       "      <th>...</th>\n",
       "      <th>multi_0_step_35_logit</th>\n",
       "      <th>multi_1_step_35_logit</th>\n",
       "      <th>multi_2_step_35_logit</th>\n",
       "      <th>multi_3_step_35_logit</th>\n",
       "      <th>multi_4_step_35_logit</th>\n",
       "      <th>multi_0_step_36_logit</th>\n",
       "      <th>multi_1_step_36_logit</th>\n",
       "      <th>multi_2_step_36_logit</th>\n",
       "      <th>multi_3_step_36_logit</th>\n",
       "      <th>multi_4_step_36_logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>6.292800e+05</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "      <td>629280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.048460</td>\n",
       "      <td>0.050175</td>\n",
       "      <td>0.050129</td>\n",
       "      <td>0.050069</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.059946</td>\n",
       "      <td>0.061269</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.074190</td>\n",
       "      <td>0.065181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991996</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>6.354401e-06</td>\n",
       "      <td>0.991996</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.279730</td>\n",
       "      <td>0.280987</td>\n",
       "      <td>0.277936</td>\n",
       "      <td>0.290519</td>\n",
       "      <td>0.276473</td>\n",
       "      <td>0.349047</td>\n",
       "      <td>0.345778</td>\n",
       "      <td>0.422694</td>\n",
       "      <td>0.448508</td>\n",
       "      <td>0.391891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>1.442169e-04</td>\n",
       "      <td>0.032936</td>\n",
       "      <td>0.017525</td>\n",
       "      <td>0.012973</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.020138</td>\n",
       "      <td>-0.127007</td>\n",
       "      <td>-0.002590</td>\n",
       "      <td>-0.121167</td>\n",
       "      <td>-0.097833</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>-0.004704</td>\n",
       "      <td>-0.013511</td>\n",
       "      <td>-0.007174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>6.914340e-07</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994545</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>7.143612e-07</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994598</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>7.167635e-07</td>\n",
       "      <td>0.994620</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.005884</td>\n",
       "      <td>0.006388</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994610</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>7.275963e-07</td>\n",
       "      <td>0.994632</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.269841</td>\n",
       "      <td>6.592434</td>\n",
       "      <td>7.232289</td>\n",
       "      <td>8.278019</td>\n",
       "      <td>7.849818</td>\n",
       "      <td>10.700899</td>\n",
       "      <td>9.918594</td>\n",
       "      <td>10.460919</td>\n",
       "      <td>10.240162</td>\n",
       "      <td>9.569431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994724</td>\n",
       "      <td>0.428390</td>\n",
       "      <td>0.438398</td>\n",
       "      <td>0.192478</td>\n",
       "      <td>2.016335e-02</td>\n",
       "      <td>0.994744</td>\n",
       "      <td>0.440211</td>\n",
       "      <td>0.431006</td>\n",
       "      <td>0.191948</td>\n",
       "      <td>0.013341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step_pred_1    step_pred_2    step_pred_3    step_pred_4  \\\n",
       "count  629280.000000  629280.000000  629280.000000  629280.000000   \n",
       "mean        0.048460       0.050175       0.050129       0.050069   \n",
       "std         0.279730       0.280987       0.277936       0.290519   \n",
       "min        -0.020138      -0.127007      -0.002590      -0.121167   \n",
       "25%         0.000075       0.000106       0.000135       0.000143   \n",
       "50%         0.000430       0.000546       0.000625       0.000731   \n",
       "75%         0.002898       0.003392       0.003745       0.004117   \n",
       "max         7.269841       6.592434       7.232289       8.278019   \n",
       "\n",
       "         step_pred_5    step_pred_6    step_pred_7    step_pred_8  \\\n",
       "count  629280.000000  629280.000000  629280.000000  629280.000000   \n",
       "mean        0.049780       0.059946       0.061269       0.069110   \n",
       "std         0.276473       0.349047       0.345778       0.422694   \n",
       "min        -0.097833      -0.000500      -0.000435      -0.004704   \n",
       "25%         0.000182       0.000202       0.000218       0.000259   \n",
       "50%         0.000841       0.000894       0.000961       0.001091   \n",
       "75%         0.004504       0.004938       0.005522       0.005884   \n",
       "max         7.849818      10.700899       9.918594      10.460919   \n",
       "\n",
       "         step_pred_9   step_pred_10  ...  multi_0_step_35_logit  \\\n",
       "count  629280.000000  629280.000000  ...          629280.000000   \n",
       "mean        0.074190       0.065181  ...               0.991996   \n",
       "std         0.448508       0.391891  ...               0.033572   \n",
       "min        -0.013511      -0.007174  ...               0.004204   \n",
       "25%         0.000295       0.000282  ...               0.994545   \n",
       "50%         0.001205       0.001272  ...               0.994598   \n",
       "75%         0.006388       0.006558  ...               0.994610   \n",
       "max        10.240162       9.569431  ...               0.994724   \n",
       "\n",
       "       multi_1_step_35_logit  multi_2_step_35_logit  multi_3_step_35_logit  \\\n",
       "count          629280.000000          629280.000000          629280.000000   \n",
       "mean                0.005320               0.002458               0.000219   \n",
       "std                 0.017600               0.013476               0.002643   \n",
       "min                 0.003765               0.001440               0.000070   \n",
       "25%                 0.003843               0.001474               0.000072   \n",
       "50%                 0.003851               0.001477               0.000072   \n",
       "75%                 0.003888               0.001493               0.000073   \n",
       "max                 0.428390               0.438398               0.192478   \n",
       "\n",
       "       multi_4_step_35_logit  multi_0_step_36_logit  multi_1_step_36_logit  \\\n",
       "count           6.292800e+05          629280.000000          629280.000000   \n",
       "mean            6.354401e-06               0.991996               0.005320   \n",
       "std             1.442169e-04               0.032936               0.017525   \n",
       "min             6.914340e-07               0.003722               0.003731   \n",
       "25%             7.143612e-07               0.994561               0.003808   \n",
       "50%             7.167635e-07               0.994620               0.003816   \n",
       "75%             7.275963e-07               0.994632               0.003857   \n",
       "max             2.016335e-02               0.994744               0.440211   \n",
       "\n",
       "       multi_2_step_36_logit  multi_3_step_36_logit  multi_4_step_36_logit  \n",
       "count          629280.000000          629280.000000          629280.000000  \n",
       "mean                0.002458               0.000219               0.000006  \n",
       "std                 0.012973               0.002653               0.000125  \n",
       "min                 0.001451               0.000072               0.000001  \n",
       "25%                 0.001484               0.000074               0.000001  \n",
       "50%                 0.001488               0.000075               0.000001  \n",
       "75%                 0.001505               0.000076               0.000001  \n",
       "max                 0.431006               0.191948               0.013341  \n",
       "\n",
       "[8 rows x 220 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model to transform predictions from  fatalities to (1) dichotomous and (2) multiclass\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "dichotomous_classifiers = []\n",
    "multi_classifiers = []\n",
    "for step in steps:\n",
    "    X = np.array(ensemble_test_df[f'step_pred_{step}'])\n",
    "    X = X.reshape(-1,1)\n",
    "    # Dichotomous\n",
    "    y_dich = np.array(ensemble_test_df['ged_gte_25']).reshape(-1, 1)\n",
    "    dich_clf = LogisticRegression(random_state=0).fit(X, y_dich)\n",
    "    dichotomous_classifiers.append(dich_clf)\n",
    "    p_dich = dich_clf.predict_proba(X)\n",
    "    ensemble_test_df['dich_step_{step}_logit'] = p_dich[:,1].ravel()\n",
    "    # Multiclass\n",
    "    y_multi = np.array(ensemble_test_df['ged_multi']).reshape(-1, 1)\n",
    "    multi_clf = LogisticRegression(random_state=0).fit(X, y_multi)\n",
    "    multi_classifiers.append(multi_clf)\n",
    "    p_multi = multi_clf.predict_proba(X)\n",
    "    for cls in [0,1,2,3,4]:\n",
    "        ensemble_test_df[f'multi_{cls}_step_{step}_logit'] = p_multi[:,cls].ravel()\n",
    "\n",
    "ensemble_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5cb221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnsembleList[0]['future_df_dichotomous'] = EnsembleList[0]['predictions_future_df'].copy() # Copy from baseline\n",
    "\n",
    "for step in steps:\n",
    "    month = EndOfHistory + step\n",
    "#    weightcol = 'step_pred_' + str(step)\n",
    "#    weights = np.array(pd.DataFrame(i_weights_df[weightcol]))\n",
    "#    EnsembleList[0]['future_df_calibrated'].loc[month] = ConstituentModels_df_w.loc[month].dot(weights).values\n",
    "    x_d = np.array(EnsembleList[0]['predictions_future_df'].loc[month]).reshape(-1,1)\n",
    "    pred_step = dichotomous_classifiers[step-1].predict_proba(x_d)\n",
    "    EnsembleList[0]['future_df_dichotomous']['step_combined'].loc[month] = pred_step[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e11082c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predstore_future_dich = level +  '_' + EnsembleList[0]['modelname'] + '_dich_f' + str(EndOfHistory)\n",
    "EnsembleList[0]['future_df_dichotomous'].forecasts.set_run(run_id)\n",
    "EnsembleList[0]['future_df_dichotomous'].forecasts.to_store(name=predstore_future_dich, overwrite = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3854ca6b",
   "metadata": {},
   "source": [
    "# Mapping future predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10bfd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import contextily as ctx\n",
    "\n",
    "from views_dataviz import color\n",
    "from views_dataviz.map import utils\n",
    "from views_dataviz.map.presets import ViewsMap\n",
    "\n",
    "import sqlalchemy as sa\n",
    "#from ingester3.config import source_db_path\n",
    "#from ingester3.Country import Country\n",
    "#from ingester3.extensions import *\n",
    "#from ingester3.ViewsMonth import ViewsMonth\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Mapper2:\n",
    "    \"\"\"\n",
    "    `Map` takes basic properties and allows the user to consecutively add\n",
    "    layers to the Map object. This makes it possible to prepare mapping\n",
    "    \"presets\" at any level of layeredness that can be built on further.\n",
    "    \n",
    "    Mapper2 allows for the customizable addition of scaling to the map. \n",
    "    -re-add the code for labels later when i can test it\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    width: Integer value for width in inches.\n",
    "    height: Integer value for height in inches.\n",
    "    bbox: List for the bbox per [xmin, xmax, ymin, ymax].\n",
    "    frame_on: Bool for whether to draw a frame around the map.\n",
    "    title: Optional default title at matplotlib's default size.\n",
    "    figure: Optional tuple of (fig, size) to use if you want to plot into an\n",
    "        already existing fig and ax, rather than making a new one.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        width,\n",
    "        height,\n",
    "        bbox=None,\n",
    "        cmap=None,\n",
    "        frame_on=True,\n",
    "        title=\"\",  # Default title without customization. (?)\n",
    "        figure=None,\n",
    "    ):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.bbox = bbox  # xmin, xmax, ymin, ymax\n",
    "        self.cmap = cmap\n",
    "        if figure is None:\n",
    "            self.fig, self.ax = plt.subplots(figsize=(self.width, self.height))\n",
    "        else:\n",
    "            self.fig, self.ax = figure\n",
    "        self.texts = []\n",
    "        self.ax.set_title(title)\n",
    "\n",
    "        if frame_on:  # Remove axis ticks only.\n",
    "            self.ax.tick_params(\n",
    "                top=False,\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                right=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=False,\n",
    "            )\n",
    "        else:\n",
    "            self.ax.axis(\"off\")\n",
    "\n",
    "        if bbox is not None:\n",
    "            self.ax.set_xlim((self.bbox[0], self.bbox[1]))\n",
    "            self.ax.set_ylim((self.bbox[2], self.bbox[3]))\n",
    "\n",
    "    def add_layer(self, gdf, map_scale=False, map_dictionary=False, cmap=None, inform_colorbar=False, **kwargs):\n",
    "        \"\"\"Add a geopandas plot to a new layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        gdf: Geopandas GeoDataFrame to plot.\n",
    "        cmap: Optional matplotlib colormap object or string reference\n",
    "            (e.g. \"viridis\").\n",
    "        inform_colorbar: Set or overwrite colorbar with the current layer.\n",
    "            Not applicable when `color` is supplied in the kwargs.\n",
    "        map_scale: set a manual scale for the map. If missing defaults to the Remco procedure. \n",
    "        map_dictionary: set manual labels for the map. If missing defaults to the default labels.\n",
    "        **kwargs: Geopandas `.plot` keyword arguments.\n",
    "        \"\"\"\n",
    "        if \"color\" in kwargs:\n",
    "            colormap = None\n",
    "        else:\n",
    "            colormap = self.cmap if cmap is None else cmap\n",
    "            if inform_colorbar and \"column\" in kwargs:\n",
    "                if hasattr(self, \"cax\"):\n",
    "                    self.cax.remove()\n",
    "                if \"vmin\" not in kwargs:\n",
    "                    self.vmin = gdf[kwargs[\"column\"]].min()\n",
    "                else:\n",
    "                    self.vmin = kwargs[\"vmin\"]\n",
    "                if \"vmax\" not in kwargs:\n",
    "                    self.vmax = gdf[kwargs[\"column\"]].max()\n",
    "                else:\n",
    "                    self.vmax = kwargs[\"vmax\"]\n",
    "        \n",
    "        try: Mapper2.add_colorbar(self, colormap, min(map_scale), max(map_scale))\n",
    "        except: Mapper2.add_colorbar(self, colormap, self.vmin, self.vmax)\n",
    "        \n",
    "        try:\n",
    "            self.ax = gdf.plot(ax=self.ax, cmap=colormap, vmin=min(map_scale), vmax=max(map_scale), **kwargs)\n",
    "        except: \n",
    "            self.ax = gdf.plot(ax=self.ax, cmap=colormap, **kwargs)\n",
    "\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def add_colorbar(\n",
    "        self,\n",
    "        cmap,\n",
    "        vmin,\n",
    "        vmax,\n",
    "        location=\"right\",\n",
    "        size=\"5%\",\n",
    "        pad=0.1,\n",
    "        alpha=1,\n",
    "        labelsize=16,\n",
    "        tickparams=None,\n",
    "    ):\n",
    "        \"\"\"Add custom colorbar to Map.\n",
    "\n",
    "        Needed since GeoPandas legend and plot axes do not align, see:\n",
    "        https://geopandas.readthedocs.io/en/latest/docs/user_guide/mapping.html\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cmap: Matplotlib colormap object or string reference (e.g. \"viridis\").\n",
    "        vmin: Minimum value of range colorbar.\n",
    "        vmax: Maximum value of range colorbar.\n",
    "        location: String for location of colorbar: \"top\", \"bottom\", \"left\"\n",
    "            or \"right\".\n",
    "        size: Size in either string percentage or number of pixels.\n",
    "        pad: Float for padding between the plot's frame and colorbar.\n",
    "        alpha: Float for alpha to apply to colorbar.\n",
    "        labelsize: Integer value for the text size of the ticklabels.\n",
    "        tickparams: Dictionary containing value-label pairs. For example:\n",
    "            {0.05: \"5%\", 0.1: \"10%\"}\n",
    "        \"\"\"\n",
    "        norm = plt.Normalize(vmin, vmax)\n",
    "        if isinstance(cmap, str):\n",
    "            cmap = plt.get_cmap(cmap)\n",
    "        cmap = color.force_alpha_colormap(cmap=cmap, alpha=alpha)\n",
    "        scalar_to_rgba = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        divider = make_axes_locatable(self.ax)\n",
    "        self.cax = divider.append_axes(location, size, pad)\n",
    "        self.cax.tick_params(labelsize=labelsize)\n",
    "        tickvalues = (\n",
    "            list(tickparams.keys()) if tickparams is not None else None\n",
    "        )\n",
    "        self.cbar = plt.colorbar(\n",
    "            scalar_to_rgba, cax=self.cax, ticks=tickvalues\n",
    "        )\n",
    "        if tickparams is not None:\n",
    "            self.cbar.set_ticklabels(list(tickparams.values()))\n",
    "        return self\n",
    "    \n",
    "    def save(\n",
    "        self, path, dpi=200, **kwargs\n",
    "    ):  # Just some defaults to reduce work.\n",
    "        \"\"\"Save Map figure to file.\n",
    "        Parameters\n",
    "        ----------\n",
    "        path: String path, e.g. \"./example.png\".\n",
    "        dpi: Integer dots per inch. Increase for higher resolution figures.\n",
    "        **kwargs: Matplotlib `savefig` keyword arguments.\n",
    "        \"\"\"\n",
    "        self.fig.savefig(path, dpi=dpi, bbox_inches=\"tight\", **kwargs)\n",
    "        plt.close(self.fig)\n",
    "        \n",
    "\n",
    "def vid2date(i):\n",
    "    year=str(1980 + i//12)\n",
    "    month=str(i%12)\n",
    "    return year+'/'+month\n",
    "        \n",
    "#def vid2date(i):\n",
    "#    year=str(ViewsMonth(i).year)\n",
    "#    month=str(ViewsMonth(i).month)\n",
    "#    return year+'/'+month\n",
    "\n",
    "#note the zip function occured earlier\n",
    "standard_scale = [np.log1p(0),np.log1p(3),np.log1p(10), np.log1p(30), np.log1p(100),  np.log1p(300)]#, np.log1p(1000), np.log1p(3000),  np.log1p(10000)]\n",
    "standard_scale_labels = ['0', '3','10', '30','100', '300']#, '1000', '3000', '10000']\n",
    "\n",
    "small_scale=[np.log1p(0),np.log1p(3),np.log1p(10), np.log1p(30), np.log1p(100),  np.log1p(300)]#, np.log1p(1000)]\n",
    "\n",
    "\n",
    "small_scale_labels = ['0', '3','10', '30','100', '300']#, '1000']\n",
    "\n",
    "small_scale_nolabels = ['', '','', '','', '', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d298265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pgm geometries\n",
    "gdf_base = gpd.read_parquet('./geometry/pgm_geometry.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5277a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cm geometries\n",
    "gdf_c = gpd.read_parquet('./geometry/cm_geometry.parquet')\n",
    "gdf_c = gdf_c.to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6faa706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repairing index in  predictions_calib_df from ensemble_cm_calib\n",
      "original: month_id priogrid_id\n",
      "fixed: month_id priogrid_gid\n",
      "Repairing index in  predictions_test_df from ensemble_cm_calib\n",
      "original: month_id priogrid_id\n",
      "fixed: month_id priogrid_gid\n"
     ]
    }
   ],
   "source": [
    "df_with_wanted_index=Datasets[0]['df']\n",
    "\n",
    "FetchData.index_check(EnsembleList[0],df_with_wanted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a029ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future prediction maps, predictions, rolling\n",
    "#path = Mydropbox + 'Projects/PredictingFatalities/maps/cm_future/'\n",
    "stepstoplot=[3,5,8,12,24,36]\n",
    "#titles = [vid2date(i) for i in stepstoplot + EndOfHistory]\n",
    "\n",
    "\n",
    "df = Ensemble['predictions_future_df'].copy()\n",
    "gdf2 = gdf_base.copy()\n",
    "df = df.join(gdf2.set_index(\"priogrid_gid\"))\n",
    "gdf3 = gpd.GeoDataFrame(df, geometry=\"geom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d4f151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/jim/Work/ViEWS/ViEWS3/projects/predicting_fatalities'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6194dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in stepstoplot:\n",
    "        month = step + EndOfHistory\n",
    "        gdf = gdf3.loc[month]\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title='Ensemble predictions as of ' + vid2date(EndOfHistory+step) + ', ' + str(step) + ' months after last month with data',\n",
    "        bbox=[-18.5, 64.0, -35.5, 43.0], \n",
    "        ).add_layer(\n",
    "        gdf=gdf,\n",
    "        map_scale=standard_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.2,\n",
    "        column='step_combined', \n",
    "        inform_colorbar=True\n",
    "        )\n",
    "        ax=m.ax\n",
    "        fg=gdf_c.plot(ax=ax,edgecolor='gray',linewidth=0.7,facecolor='None')\n",
    "        \n",
    "        m.cbar.set_ticks(standard_scale)\n",
    "        m.cbar.set_ticklabels(standard_scale_labels)\n",
    "\n",
    "#        m.save(f'{overleafpath}Figures/Future/PredictionMap_cm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')\n",
    "\n",
    "        m.save(f'{path}PredictionMap_pgm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8575e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in stepstoplot:\n",
    "        month = step + EndOfHistory\n",
    "        gdf = gdf3.loc[month]\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title='Ensemble predictions as of ' + vid2date(EndOfHistory+step) + ', ' + str(step) + ' months after last month with data',\n",
    "        bbox=[29.446846321370213, 50.987309710685814, 1.1561557161401845, 18.29970129951559], \n",
    "        ).add_layer(\n",
    "        gdf=gdf,\n",
    "        map_scale=standard_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.2,\n",
    "        column='step_combined', \n",
    "        inform_colorbar=True\n",
    "        )\n",
    "        ax=m.ax\n",
    "        fg=gdf_c.plot(ax=ax,edgecolor='gray',linewidth=1.0,facecolor='None')\n",
    "        figure=m.fig\n",
    "        fontdict={'fontsize':20}\n",
    "        figure.text(0.4,0.45,'ETHIOPIA',fontdict=fontdict,color='black')\n",
    "        figure.text(0.2,0.7,'SUDAN',fontdict=fontdict,color='black')\n",
    "        figure.text(0.15,0.35,'S. SUDAN',fontdict=fontdict,color='black')\n",
    "        figure.text(0.65,0.5,'SOMALIA',fontdict=fontdict,color='black')\n",
    "        figure.text(0.35,0.25,'KENYA',fontdict=fontdict,color='black')\n",
    "        \n",
    "        m.cbar.set_ticks(standard_scale)\n",
    "        m.cbar.set_ticklabels(standard_scale_labels)\n",
    "\n",
    "#        m.save(f'{overleafpath}Figures/Future/PredictionMap_cm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')\n",
    "\n",
    "        m.save(f'{path}PredictionMap_Ethiopia_pgm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08e14c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in stepstoplot:\n",
    "        month = step + EndOfHistory\n",
    "        gdf = gdf3.loc[month]\n",
    "        m=Mapper2(\n",
    "        width=10,\n",
    "        height=10,\n",
    "        frame_on=True,\n",
    "        title='Ensemble predictions as of ' + vid2date(EndOfHistory+step) + ', ' + str(step) + ' months after last month with data',\n",
    "        bbox=[-2.3019466946294584, 20.374695512438592, 1.103974761908613, 16.794164972712068], \n",
    "        ).add_layer(\n",
    "        gdf=gdf,\n",
    "        map_scale=standard_scale,\n",
    "        cmap=\"rainbow\",\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.2,\n",
    "        column='step_combined', \n",
    "        inform_colorbar=True\n",
    "        )\n",
    "        ax=m.ax\n",
    "        fg=gdf_c.plot(ax=ax,edgecolor='gray',linewidth=1.0,facecolor='None')\n",
    "        figure=m.fig\n",
    "        fontdict={'fontsize':20}\n",
    "        figure.text(0.4,0.45,'NIGERIA',fontdict=fontdict,color='black')\n",
    "        figure.text(0.4,0.7,'NIGER',fontdict=fontdict,color='black')\n",
    "        figure.text(0.5,0.35,'CAMEROON',fontdict=fontdict,color='black')\n",
    "        figure.text(0.7,0.60,'CHAD',fontdict=fontdict,color='black')\n",
    "        figure.text(0.7,0.4,'C.A.R.',fontdict=fontdict,color='black')\n",
    "        figure.text(0.15,0.60,'B. FASO',fontdict=fontdict,color='black')\n",
    "        \n",
    "        m.cbar.set_ticks(standard_scale)\n",
    "        m.cbar.set_ticklabels(standard_scale_labels)\n",
    "\n",
    "#        m.save(f'{overleafpath}Figures/Future/PredictionMap_cm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')\n",
    "\n",
    "        m.save(f'{path}PredictionMap_Nigeria_pgm_ensemble_standard_scale_r{EndOfHistory}_m{month}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f266a",
   "metadata": {},
   "source": [
    "# Changes to 3- and 6-month forecasts, and since last actual observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d048ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_45_pgm_ensemble_cm_calib_f504.parquet\n",
      "Trouble reading forecasts issued three months ago\n"
     ]
    }
   ],
   "source": [
    "# Reading in data for mapping\n",
    "# Predictions now and then\n",
    "predstore_then = level +  '_' + EnsembleList[0]['modelname'] + '_f' + str(EndOfHistory-3)\n",
    "\n",
    "df_now = EnsembleList[0]['predictions_future_df'].copy()\n",
    "\n",
    "df_then=ViewsMetadata().with_name('ensemble_cm_calib_f'+str(EndOfHistory-3)).fetch()\n",
    "\n",
    "try:\n",
    "    df_then = pd.DataFrame.forecasts.read_store(run=run_id, name=predstore_then)\n",
    "except:\n",
    "    print('Trouble reading forecasts issued three months ago')\n",
    "    \n",
    "# Actuals\n",
    "\n",
    "df_lastobserved = Datasets[0]['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log of mean non-logged fatalities, past six months\n",
    "df_observed = df_lastobserved.loc[EndOfHistory]\n",
    "df_observed['ged_sb_0'] = np.expm1(df_observed['ln_ged_sb'])\n",
    "df_observed['ged_sum'] = df_observed['ged_sb_0']\n",
    "for t in [1,2,3,4,5]:\n",
    "    colname = 'ged_sb_' + str(t)\n",
    "    df_observed[colname] = np.expm1(df_lastobserved.loc[EndOfHistory-t]['ln_ged_sb'])\n",
    "    df_observed['ged_sum'] = df_observed['ged_sum'] + df_observed[colname]\n",
    "df_observed['ln_ged_sum'] = np.log1p(df_observed['ged_sum']/6)\n",
    "#df_observed.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb460b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepsForward = [\n",
    "{\n",
    "    'Step': 3,\n",
    "    'df_now': df_now.loc[EndOfHistory + 3],\n",
    "    'df_then': df_then.loc[EndOfHistory - 3 + 3]\n",
    "},\n",
    "{\n",
    "    'Step': 6,\n",
    "    'df_now': df_now.loc[EndOfHistory + 6],\n",
    "    'df_then': df_then.loc[EndOfHistory - 3 + 6]\n",
    "},\n",
    "]\n",
    "engine = sa.create_engine(source_db_path)\n",
    "#predictors_df = data_vdem_short.loc[EndOfHistory]\n",
    "#predictors_df_3m = data_vdem_short.loc[EndOfHistory-3]\n",
    "\n",
    "for s in StepsForward:\n",
    "    s['df_now'].rename(columns={'step_combined':'Now'}, inplace=True)\n",
    "    s['df_then'].rename(columns={'step_combined':'Then'}, inplace=True)\n",
    "    s['df'] = pd.concat([s['df_now'],s['df_then'],df_observed['ln_ged_sum']],axis=1)\n",
    "    s['df']['Change_in_prediction'] = s['df']['Now']-s['df']['Then']\n",
    "    s['df']['Change_since_last_observed'] = s['df']['Now']-s['df']['ln_ged_sum']\n",
    "    \n",
    "#    # Surrogate model change\n",
    "#    for sm in SurrogateModelList:\n",
    "#        if sm['Step'] == s['Step']:\n",
    "#            s['sdf'] = predictors_df[sm['Columns']]\n",
    "#            s['sdf'][sm['Predcolname']] = sm['GAM'].predict(predictors_df[sm['Columns']])\n",
    "#            s['sdf_3m'] = predictors_df_3m[sm['Columns']]\n",
    "#            s['sdf_3m'][sm['Predcolname']] = sm['GAM'].predict(predictors_df_3m[sm['Columns']])\n",
    "#            print(sm['Step'],sm['Predcolname'])\n",
    "#            dfcolname = sm['Predcolname'][:-2] + '_ch3m'\n",
    "#            s['df'][dfcolname] = s['sdf'][sm['Predcolname']] - s['sdf_3m'][sm['Predcolname']]\n",
    "    \n",
    "    s['gdf'] = gdf_base\n",
    "    s['gdf'] = s['gdf'].to_crs(4326)\n",
    "\n",
    "    s['gdf_t'] = s['df'].join(s['gdf'].set_index(\"priogrid_gid\"))\n",
    "    s['gdf'] = gpd.GeoDataFrame(s['gdf_t'], geometry=\"geom\")\n",
    "    \n",
    "    \n",
    "StepsForward[0]['gdf'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aeb3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickvalues = np.array([-80,-50,-20,0,20,50,100,200,500])\n",
    "print(tickvalues)\n",
    "ticklabels=[str(tv) for tv in tickvalues]\n",
    "tickvalues = np.log((100+tickvalues)/100)\n",
    "print(tickvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e22c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 3\n",
    "\n",
    "tickvalues=np.array([-300,-30,-3,3,30,300])\n",
    "ticklabels=[str(tv) for tv in tickvalues]\n",
    "\n",
    "tickvalues=np.sign(tickvalues)*np.log1p(np.abs(tickvalues)+1)\n",
    "#print(tickvalues)\n",
    "tickvalues = np.array([-83,-80,-50,-20,0,20,50,100,200,500])\n",
    "ticklabels=[str(tv) for tv in tickvalues]\n",
    "ticklabels[0] = \"\"\n",
    "tickvalues = np.log((100+tickvalues)/100)\n",
    "\n",
    "\n",
    "t0s=range(506,507) # From start of month A, to start of (but not including) month B\n",
    "bbox=\"africa_middle_east\"\n",
    "cmap='bwr'#'rainbow'\n",
    "for s in StepsForward:\n",
    "    for column in ['Change_in_prediction','Change_since_last_observed']:\n",
    "        titlestring=''\n",
    "        plot = ViewsMap(\n",
    "            width=10,\n",
    "            label=f\"{column}, s= {s['Step']}\",\n",
    "            title=\"\",\n",
    "            scale=None,\n",
    "            bbox=bbox\n",
    "        ).add_layer(\n",
    "            s['gdf'],\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.1,\n",
    "            column=column,\n",
    "        inform_colorbar=True,\n",
    "        cmap=cmap,\n",
    "        vmin=tickvalues[0],vmax=tickvalues[-1]\n",
    "    )\n",
    "\n",
    "        ax=plot.ax\n",
    "        fg=s['gdf'].plot(ax=ax,edgecolor='black',linewidth=0.2,facecolor='None')\n",
    "       # fg=gdf_c.plot(ax=ax,edgecolor='gray',linewidth=1.0,facecolor='None')\n",
    "        figure=plot.fig\n",
    "        fontdict={'fontsize':20}\n",
    "        fig=plot.fig\n",
    "\n",
    "        plot.cbar.set_ticks(tickvalues)\n",
    "        plot.cbar.set_ticklabels(ticklabels)\n",
    "        if abs(delta)==1:\n",
    "            mnth='month'\n",
    "        else:\n",
    "            mnth='months'\n",
    "        plot.cbar.set_label(f'Percent change in {column} over past '+str(delta)+' '+mnth)\n",
    "\n",
    "#        plot.save(overleafpath+'Figures/Future/'+column+str(s['Step'])+'_r' + str(EndOfHistory) +'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f20e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
